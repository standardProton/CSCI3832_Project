{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the trained models on our handmade dataset\n",
    "\n",
    "Alex Ludwigson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import os \n",
    "import io\n",
    "import transformers\n",
    "from transformers import GPT2Config, GPT2ForSequenceClassification, GPT2Tokenizer, AutoTokenizer,  AutoModelForSequenceClassification\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer's performance on the handmade dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the -0.038194 -0.24487 0.72812 -0.39961 0.083172 0.043953 -0.39141 0.3344 -0.57545 0.087459 0.28787 -0.06731 0.30906 -0.26384 -0.13231 -0.20757 0.33395 -0.33848 -0.31743 -0.48336 0.1464 -0.37304 0.34577 0.052041 0.44946 -0.46971 0.02628 -0.54155 -0.15518 -0.14107 -0.039722 0.28277 0.14393 0.23464 -0.31021 0.086173 0.20397 0.52624 0.17164 -0.082378 -0.71787 -0.41531 0.20335 -0.12763 0.41367 0.55187 0.57908 -0.33477 -0.36559 -0.54857 -0.062892 0.26584 0.30205 0.99775 -0.80481 -3.0243 0.01254 -0.36942 2.2167 0.72201 -0.24978 0.92136 0.034514 0.46745 1.1079 -0.19358 -0.074575 0.23353 -0.052062 -0.22044 0.057162 -0.15806 -0.30798 -0.41625 0.37972 0.15006 -0.53212 -0.2055 -1.2526 0.071624 0.70565 0.49744 -0.42063 0.26148 -1.538 -0.30223 -0.073438 -0.28312 0.37104 -0.25217 0.016215 -0.017099 -0.38984 0.87424 -0.72569 -0.51058 -0.52028 -0.1459 0.8278 0.27062\n",
      "\n",
      "Loaded 400000 words from glove\n",
      "0\n",
      "[-0.038194 -0.24487   0.72812  -0.39961   0.083172  0.043953 -0.39141\n",
      "  0.3344   -0.57545   0.087459  0.28787  -0.06731   0.30906  -0.26384\n",
      " -0.13231  -0.20757   0.33395  -0.33848  -0.31743  -0.48336   0.1464\n",
      " -0.37304   0.34577   0.052041  0.44946  -0.46971   0.02628  -0.54155\n",
      " -0.15518  -0.14107  -0.039722  0.28277   0.14393   0.23464  -0.31021\n",
      "  0.086173  0.20397   0.52624   0.17164  -0.082378 -0.71787  -0.41531\n",
      "  0.20335  -0.12763   0.41367   0.55187   0.57908  -0.33477  -0.36559\n",
      " -0.54857  -0.062892  0.26584   0.30205   0.99775  -0.80481  -3.0243\n",
      "  0.01254  -0.36942   2.2167    0.72201  -0.24978   0.92136   0.034514\n",
      "  0.46745   1.1079   -0.19358  -0.074575  0.23353  -0.052062 -0.22044\n",
      "  0.057162 -0.15806  -0.30798  -0.41625   0.37972   0.15006  -0.53212\n",
      " -0.2055   -1.2526    0.071624  0.70565   0.49744  -0.42063   0.26148\n",
      " -1.538    -0.30223  -0.073438 -0.28312   0.37104  -0.25217   0.016215\n",
      " -0.017099 -0.38984   0.87424  -0.72569  -0.51058  -0.52028  -0.1459\n",
      "  0.8278    0.27062 ]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n",
      "  text_label                                               text  label\n",
      "0       Spam  Subject: ðŸŽ‰ Exclusive Offer: Win a Free Vacatio...      1\n",
      "1        Ham  Subject: Invitation to Attend Our Annual Confe...      0\n",
      "2       Spam  Welcome to the CollegeXpress community! Weâ€™re ...      1\n",
      "3       Spam  Spring into savings with exclusive deals at Be...      1\n",
      "4        Ham  Your password for the [Company Name] career si...      0\n",
      "accuracy: 22/30 = 0.7333333333333333\n",
      "True positive: 0.4666666666666667\n",
      "False positive: 0.16666666666666666\n",
      "True negative: 0.26666666666666666\n",
      "False negative: 0.1\n",
      "(P, R, F-Score) = (0.7368421052631579, 0.8235294117647058, 0.7777777777777778)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7333333333333333"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_file = \"./datasets/glove.6B.100d.txt\" #or 50d\n",
    "\n",
    "embeddings_dict = {}\n",
    "\n",
    "with open(glove_file, 'r', encoding='utf8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i == 0:\n",
    "            print(line)\n",
    "        line = line.strip().split(' ')\n",
    "        word = line[0]\n",
    "        embed = np.asarray(line[1:], \"float\")\n",
    "\n",
    "        embeddings_dict[word] = embed\n",
    "\n",
    "print('Loaded {} words from glove'.format(len(embeddings_dict)))\n",
    "\n",
    "embedding_matrix = np.zeros((len(embeddings_dict)+2, 100)) #add 1 for padding\n",
    "\n",
    "word2id = {}\n",
    "for i, word in enumerate(embeddings_dict.keys()):\n",
    "\n",
    "    word2id[word] = i                                #Map each word to an index\n",
    "    embedding_matrix[i] = embeddings_dict[word]      #That index holds the Glove embedding in the embedding matrix\n",
    "\n",
    "# Our joint vocabulary for both models / sanity check to see if we've loaded it correctly:\n",
    "print(word2id['the'])\n",
    "print(embedding_matrix[word2id['the']])\n",
    "\n",
    "word2id['<pad>'] = embedding_matrix.shape[0] - 2\n",
    "word2id['<start>'] = embedding_matrix.shape[0] - 1\n",
    "print(embedding_matrix[word2id['<pad>']])\n",
    "\n",
    "max_length = 120 #inclusive of start token\n",
    "start_id = word2id['<start>']\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_matrix, model_size, n_heads, n_layers, hidden_size, embedding_dims=100, vocab_size=None):\n",
    "        super().__init__()\n",
    "\n",
    "        if not (embedding_matrix is None): #glove\n",
    "            self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_matrix))\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(vocab_size, embedding_dims)\n",
    "        self.pos_encoding = PositionalEncoding(embedding_dims, max_length)\n",
    "        self.input_linear = nn.Linear(embedding_dims, model_size)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(model_size, n_heads, hidden_size, batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layers, n_layers)\n",
    "        #self.encoder = nn.Transformer(encoder_layers, n_layers, batch_first=True)\n",
    "        self.output_hidden_1 = nn.Linear(model_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output_hidden_2 = nn.Linear(hidden_size, 2) #binary classification\n",
    "        self.model_size = model_size\n",
    "\n",
    "        #initialize\n",
    "        initrange = 0.1\n",
    "        self.input_linear.weight.data.uniform_(-initrange, initrange)\n",
    "        self.input_linear.bias.data.zero_()\n",
    "        self.output_hidden_1.weight.data.uniform_(-initrange, initrange)\n",
    "        self.output_hidden_1.bias.data.zero_()\n",
    "        self.output_hidden_2.weight.data.uniform_(-initrange, initrange)\n",
    "        self.output_hidden_2.bias.data.zero_()\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        #print(\"intput.shape: \", input.shape, len(input.shape))\n",
    "        input = (self.embedding(input) * math.sqrt(self.model_size)) #recommended from documentation\n",
    "        input = self.pos_encoding(input)\n",
    "        #print(\"input after poe:\", input.shape)\n",
    "\n",
    "        input = self.input_linear(input) #get a representation that has the model size for the positionally encoded embeddings\n",
    "        #print(\"after input linear: \", input.shape)\n",
    "        \n",
    "        output = self.encoder(input)[:,0] #take the last vector\n",
    "        #print(\"after encoder: \", output.shape)\n",
    "        output = self.output_hidden_1(output)\n",
    "\n",
    "        output = self.relu(output)\n",
    "        output = self.output_hidden_2(output)\n",
    "\n",
    "        #print(\"after linear:\", output.shape)\n",
    "\n",
    "        return output\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, model_size, max_len): #from torch documentation\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, model_size, 2) * (-math.log(10000.0) / model_size))\n",
    "        pe = torch.zeros(max_len, 1, model_size)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "#Define hyperparameters\n",
    "epochs = 6\n",
    "batch_size = 32\n",
    "print_frequency = 250\n",
    "n_heads = 2\n",
    "n_layers = 2\n",
    "model_size = 28\n",
    "hidden_size = 48\n",
    "pos_weight_coeff = 1.05\n",
    "\n",
    "\n",
    "def predict(model, valid_dataloader):\n",
    "\n",
    "    softmax = nn.Softmax()\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    sigmoid = nn.Sigmoid()\n",
    "\n",
    "    total_examples = 0\n",
    "    total_positive = 0\n",
    "    total_negative = 0\n",
    "\n",
    "    true_positive = 0\n",
    "    false_positive = 0\n",
    "    true_negative = 0\n",
    "    false_negative = 0\n",
    "\n",
    "    for x, y in valid_dataloader:\n",
    "        x = x.squeeze()\n",
    "        if (len(x.shape) == 0): continue\n",
    "        output = model(x)\n",
    "        output = softmax(output)\n",
    "\n",
    "        for i in range(output.shape[0]):\n",
    "            if (output[i][0].item() >= 0.5):\n",
    "                if (y[i].item() == 0):\n",
    "                    true_negative += 1\n",
    "                    total_negative += 1\n",
    "                else:\n",
    "                    false_negative += 1\n",
    "                    total_positive += 1\n",
    "                    #print(y)\n",
    "            else:\n",
    "                if (y[i].item() == 0):\n",
    "                    false_positive += 1\n",
    "                    total_negative += 1\n",
    "                    #print(y)\n",
    "                else:\n",
    "                    true_positive += 1\n",
    "                    total_positive += 1\n",
    "        total_examples += output.shape[0]\n",
    "        #print(\"total examples:\", total_examples, \"; T+:\", true_positive, \"; F+:\", false_positive, \"; T-:\", true_negative, \"; F-:\", false_negative)\n",
    "\n",
    "    accuracy = (true_positive + true_negative) / total_examples\n",
    "    t_p = true_positive/total_examples\n",
    "    f_p = false_positive/total_examples\n",
    "    t_n = true_negative/total_examples\n",
    "    f_n = false_negative/total_examples\n",
    "    p = true_positive/(true_positive + false_positive)\n",
    "    r = true_positive/(true_positive + false_negative)\n",
    "    f_score = (2*p*r)/(p+r)\n",
    "\n",
    "    print('accuracy: %s/%s = %s' % (true_positive+true_negative, total_examples, (true_positive + true_negative) / total_examples))\n",
    "    print('True positive: %s' % t_p)\n",
    "    print(\"False positive: %s\" % f_p)\n",
    "    print('True negative: %s' % t_n)\n",
    "    print(\"False negative: %s\" % f_n)\n",
    "    print(\"(P, R, F-Score) = (%s, %s, %s)\\n\" % (p, r, f_score))\n",
    "    return accuracy\n",
    "\n",
    "def tokenize_example(line):\n",
    "    example = [start_id]\n",
    "    tokenized = nltk.word_tokenize(line)\n",
    "    i = 0\n",
    "    for token in tokenized:\n",
    "        if not (token in word2id): continue #not using <unk> for spam dataset\n",
    "        i += 1\n",
    "        if (i >= max_length): break\n",
    "        example.append(word2id[token])\n",
    "        \n",
    "    #add padding\n",
    "    padding = word2id[\"<pad>\"]\n",
    "    for i in range(max_length - len(example)):\n",
    "        example.append(padding)\n",
    "    return np.array(example)\n",
    "\n",
    "def tokenize(df):\n",
    "    examples = []\n",
    "    for index, row in df.iterrows():\n",
    "        example = tokenize_example(row[\"text\"])\n",
    "        if (len(example) > 0 and len(example.shape) > 0): examples.append((example, row[\"label\"]))\n",
    "    return examples\n",
    "\n",
    "#load the state dict \n",
    "transform = TransformerModel(embedding_matrix, model_size=model_size, n_heads=n_heads, n_layers=n_layers, hidden_size=hidden_size)\n",
    "transform.load_state_dict(torch.load('./trained_models/spam.pt'))\n",
    "#read the file\n",
    "spam_hm = pd.read_csv(\"./HomebrewDataset.csv\")\n",
    "print(spam_hm.head())\n",
    "spam_hm_tok = tokenize(spam_hm)\n",
    "spam_valid_dataloader = torch.utils.data.DataLoader(spam_hm_tok, batch_size=batch_size)\n",
    "predict(transform, spam_valid_dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bert's performance on the handmade dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:06<00:00,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY:\n",
      "0.9333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def remove_doublequotes(file_dir): # \n",
    "    raw_file_str = ''\n",
    "    with open(file_dir, 'r', encoding='utf-8') as f:\n",
    "        raw_file_str = f.read().replace('\"\"', '\"')\n",
    "    with open(file_dir, 'w', encoding='utf-8') as f:\n",
    "        f.write(raw_file_str)\n",
    "\n",
    "#partition a dictionary\n",
    "def split_dict (dict1, index):\n",
    "    dict1c = dict1\n",
    "    dict1 = dict(list(dict1c.items())[index:])\n",
    "    dict2 = dict(list(dict1c.items())[:index])\n",
    "    return dict1, dict2\n",
    "\n",
    "device = torch.device(\"cpu\") #sets your device. Code will run at a snails pace without gpu\n",
    "\n",
    "\n",
    "\n",
    "class Datasets(Dataset):\n",
    "    def __init__ (self, testpath=None, Emails = None, size =None, final_data = None , data_processed=False): \n",
    "\n",
    "        if (data_processed):\n",
    "            self.length = len(final_data)\n",
    "            self.test_set = final_data\n",
    "            self.set_labels = [self.test_set[x] for x in self.test_set]\n",
    "            self.set_text = list (self.test_set.keys())\n",
    "            return\n",
    "\n",
    "        if Emails == False:\n",
    "            remove_doublequotes(testpath)\n",
    "\n",
    "\n",
    "        if (size):\n",
    "            self.test_set = pd.read_csv(testpath, nrows = size)\n",
    "        else: \n",
    "            self.test_set = pd.read_csv(testpath)\n",
    " \n",
    "        if (Emails == True):\n",
    "            self.test_set = self.test_set.set_index('text')['label'].to_dict()\n",
    "\n",
    "        else:\n",
    "            self.test_set['Unnamed: 0'] = self.test_set ['Unnamed: 0'].apply(lambda x : 2 - x)\n",
    "            self.test_set =  self.test_set.set_index('text_label')['Unnamed: 0'].to_dict() \n",
    "\n",
    "        self.length = len (self.test_set)\n",
    "\n",
    "        self.set_labels = [self.test_set[x] for x in self.test_set]\n",
    "        self.set_text = list (self.test_set.keys())\n",
    "\n",
    "        return\n",
    "    #homework 3 inspired validation data spilt function\n",
    "    def split(self, ratio = .8 ):\n",
    "        index = int(ratio*self.length)\n",
    "\n",
    "        split,self.test_set = split_dict(self.test_set, index)\n",
    "\n",
    "        self.set_labels = self.set_labels[:index]\n",
    "        self.set_text = self.set_text[:index]\n",
    "        self.length = len(self.test_set)\n",
    "\n",
    "        return split\n",
    "    #functions required by pytorch for handling data\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {'text': self.set_text[index], 'label': self.set_labels[index]}\n",
    "    \n",
    "\n",
    "class _tokenize(object):\n",
    "    def __init__(self,  use_tokenizer, max=512):\n",
    "         self.use_tokenizer = use_tokenizer\n",
    "         self.max_sequence_len =max\n",
    "    #basically just calls the tokenizer, returning embeddings  dict\n",
    "    def __call__(self, data):\n",
    "        text= [x['text'] for x in data]\n",
    "        label = [x ['label'] for x in data]\n",
    "\n",
    "\n",
    "        embeddings = self.use_tokenizer(text=text, return_tensors = \"pt\", padding = True, truncation= True, max_length = self.max_sequence_len)\n",
    "        embeddings.update({'labels' : torch.tensor(label)})\n",
    "        return embeddings\n",
    "    \n",
    "def calculate_stats(labels, predictions):\n",
    "    acc = 0.0\n",
    "    fp =0.0\n",
    "    fn = 0.0\n",
    "    tp =0.0\n",
    "    tn = 0.0\n",
    "    size = len(labels)\n",
    "    counter = 0\n",
    "\n",
    "    for x in labels:\n",
    "        if x == 1 and predictions[counter] == 1:\n",
    "            tp+=1\n",
    "            acc +=1\n",
    "        elif x == 0 and predictions[counter] == 0:\n",
    "            tn+=1\n",
    "            acc+=1\n",
    "        elif x == 1:\n",
    "            fp  +=1\n",
    "        elif x == 0:\n",
    "            fn +=1 \n",
    "        counter +=1\n",
    "\n",
    "    return [acc/size, tp/size, tn/size, fp/size, fn/size]\n",
    "\n",
    "def test (model, data, device, ):\n",
    "    print (\"Evaluating\")\n",
    "\n",
    "    total_loss = 0.0\n",
    "    predictions = []\n",
    "    labels= []\n",
    "\n",
    "    model.eval()\n",
    "    #print(data.get_item(0))\n",
    "    for batch in tqdm (data, total=len(data)):\n",
    "        labels += batch['labels'].numpy().flatten().tolist()\n",
    "        batch = {i:j.type(torch.long).to(device) for i,j in batch.items()}\n",
    "        with torch.no_grad():\n",
    "\n",
    "\n",
    "            model_out = model(**batch)\n",
    "            loss,logits =model_out[:2]\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            logits = logits.detach().cpu().numpy() \n",
    "\n",
    "            predictions  += logits.argmax(axis = -1).flatten().tolist()\n",
    "    total_loss = total_loss/len(data)\n",
    "\n",
    "\n",
    "    stats= calculate_stats (labels, predictions)\n",
    "\n",
    "    return total_loss, stats\n",
    "\n",
    "\n",
    "berto = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert = AutoModelForSequenceClassification.from_pretrained('./trained_models/bert')#f model is on gpu, ignore this\n",
    "bert.to(device)\n",
    "bertoken = _tokenize(berto)\n",
    "homebrewdataset = Datasets(testpath='./HomebrewDataset.csv', Emails=True)\n",
    "homebrew_test = DataLoader(homebrewdataset, batch_size= 1, shuffle=False, collate_fn = bertoken)\n",
    "print(len(homebrew_test))\n",
    "optimizer = torch.optim.AdamW(bert.parameters(), lr= 2e-5, eps = 1e-8)\n",
    "steps = len(homebrew_test)\n",
    "scheduler = transformers.get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0 , num_training_steps = steps)\n",
    "\n",
    "\n",
    "v_loss, stats_test = test(bert,homebrew_test, device)\n",
    "print(\"ACCURACY:\")\n",
    "print(stats_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regressions's performance on handmade dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Homebrew Test Data Accuracy: 0.5333333333333333\n",
      "[[10  3]\n",
      " [11  6]]\n",
      "Homebrew Test Data Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.77      0.59        13\n",
      "           1       0.67      0.35      0.46        17\n",
      "\n",
      "    accuracy                           0.53        30\n",
      "   macro avg       0.57      0.56      0.52        30\n",
      "weighted avg       0.58      0.53      0.52        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_curve, auc, precision_recall_curve, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "split_ratio = 0.8\n",
    "\n",
    "# Load datasets\n",
    "spam_test = pd.read_csv('./datasets/SpamHam/test.csv').fillna('')\n",
    "spam_test['label'] = spam_test['label']\n",
    "\n",
    "\n",
    "spam_ftrain = pd.read_csv('./datasets/SpamHam/train.csv').fillna('')\n",
    "spam_ftrain['label'] = spam_ftrain['label']\n",
    "spamsize = int(split_ratio*spam_ftrain.shape[0])\n",
    "spam_train=spam_ftrain.iloc[:spamsize]\n",
    "spam_valid=spam_ftrain.iloc[spamsize:]\n",
    "\n",
    "urls_test = pd.read_csv('datasets/PhishingURLs/test.csv').fillna('')\n",
    "urls_test['label'] = urls_test['label'].apply(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "urls_ftrain = pd.read_csv('datasets/PhishingURLs/test.csv').fillna('')\n",
    "urls_ftrain['label'] = urls_ftrain['label'].apply(lambda x: 1 if x == 1 else 0)\n",
    "urlsize = int(split_ratio*spam_ftrain.shape[0])\n",
    "urls_train=urls_ftrain.iloc[:urlsize]\n",
    "urls_valid=urls_ftrain.iloc[urlsize:]\n",
    "\n",
    "homebrew_data = pd.read_csv('HomebrewDataset.csv').fillna('')\n",
    "homebrew_data['label'] = homebrew_data['label'].apply(lambda x: 1 if x==1 else 0)\n",
    "\n",
    "# Split each dataset into training and testing sets\n",
    "#spam_train, spam_test = train_test_split(spam_full, test_size=0.2, random_state=42)\n",
    "#urls_train, urls_test = train_test_split(urls_full, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Combine the training data from all datasets\n",
    "#combined_train = pd.concat([spam_train, urls_train], ignore_index=True)\n",
    "#combined_valid = pd.concat([spam_valid, urls_valid], ignore_index=True)\n",
    "# Feature extraction for combined training data\n",
    "X_train_S = tfidf_vectorizer.fit_transform(spam_train['text'])\n",
    "y_train_S = spam_train['label']\n",
    "X_valid_S = tfidf_vectorizer.fit_transform(spam_valid['text'])\n",
    "y_valid_S = spam_valid['label']\n",
    "\n",
    "X_train_U = tfidf_vectorizer.fit_transform(urls_train['text'])\n",
    "y_train_U = spam_train['label']\n",
    "X_valid_U = tfidf_vectorizer.fit_transform(urls_valid['text'])\n",
    "y_valid_U = spam_valid['label']\n",
    "# Train Logistic Regression model\n",
    "#print(y_train)\n",
    "#print(X_train)\n",
    "model = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "model.fit(X_train_S, y_train_S)\n",
    "model.fit(X_train_U, y_train_U)\n",
    "\n",
    "def evaluate_model(X, y, model, dataset_name):\n",
    "    predictions = model.predict(X)\n",
    "    accuracy = accuracy_score(y, predictions)\n",
    "    conf_matrix = confusion_matrix(y, predictions)\n",
    "\n",
    "\n",
    "    print(f\"\\n{dataset_name} Accuracy:\", accuracy)\n",
    "    print(conf_matrix)\n",
    "    print(f\"{dataset_name} Classification Report:\\n\", classification_report(y, predictions))\n",
    "\n",
    "X_homebrew_test = tfidf_vectorizer.transform(homebrew_data['text'])\n",
    "y_homebrew_test = homebrew_data['label']\n",
    "evaluate_model(X_homebrew_test, y_homebrew_test, model, \"Homebrew Test Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
