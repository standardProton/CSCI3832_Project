{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-2 and Bert finetuning comparisions\n",
    "\n",
    "\n",
    "Aaron Semones\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy \n",
    "import os \n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import io\n",
    "import transformers\n",
    "from tqdm import tqdm\n",
    "from transformers import GPT2Config, GPT2ForSequenceClassification, GPT2Tokenizer, AutoTokenizer,  AutoModelForSequenceClassification\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libaries. NOTES: This notebook has printouts for whether content is safe, not whether it is unsafe. That means any true/false postives and true/false negatives should be swapped when comparing to other document. Running this code without a gpu could take literal months, so ensure a gpu is configured.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    " # formatting function for phishing dataset\n",
    "def remove_doublequotes(file_dir): # \n",
    "    raw_file_str = ''\n",
    "    with open(file_dir, 'r', encoding='utf-8') as f:\n",
    "        raw_file_str = f.read().replace('\"\"', '\"')\n",
    "    with open(file_dir, 'w', encoding='utf-8') as f:\n",
    "        f.write(raw_file_str)\n",
    "        \n",
    "#partition a dictionary\n",
    "def split_dict (dict1, index):\n",
    "    dict1c = dict1\n",
    "    dict1 = dict(list(dict1c.items())[index:])\n",
    "    dict2 = dict(list(dict1c.items())[:index])\n",
    "    return dict1, dict2\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Misc. helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") #sets your device. Code will run at a snails pace without gpu\n",
    "\n",
    "\n",
    "\n",
    "class Datasets(Dataset):\n",
    "    def __init__ (self, testpath=None, Emails = None, size =None, final_data = None , data_processed=False): \n",
    "        '''testpath is the path of your csv file, emails is a bool for handling oddities with phising ds\n",
    "        size is the desired num_entries, final_data is for turning already pre-processed data into a dataset for loading (ie validiation set),\n",
    "        dataprocessed is the bool controlling that functionalty\n",
    "        \n",
    "        \n",
    "        Members:\n",
    "        \n",
    "        length is number of examples\n",
    "        test_set is a dict of the entire set\n",
    "        set_labels is a list of the labels\n",
    "        set_text is a list of the text\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        if (data_processed):\n",
    "            self.length = len(final_data)\n",
    "            self.test_set = final_data\n",
    "            self.set_labels = [self.test_set[x] for x in self.test_set]\n",
    "            self.set_text = list (self.test_set.keys())\n",
    "            return\n",
    "        \n",
    "        if Emails == False:\n",
    "            remove_doublequotes(testpath)\n",
    "        \n",
    "        \n",
    "        if (size):\n",
    "            self.test_set = pd.read_csv(testpath, nrows = size)\n",
    "        else: \n",
    "            self.test_set = pd.read_csv(testpath)\n",
    " \n",
    "        if (Emails == True):\n",
    "            self.test_set = self.test_set.set_index('text')['label'].to_dict()\n",
    "        \n",
    "        else:\n",
    "            self.test_set['label'] = self.test_set ['label'].apply(lambda x : 2 - x)\n",
    "            self.test_set =  self.test_set.set_index('text')['label'].to_dict() \n",
    "            \n",
    "        self.length = len (self.test_set)\n",
    "        \n",
    "        self.set_labels = [self.test_set[x] for x in self.test_set]\n",
    "        self.set_text = list (self.test_set.keys())\n",
    "        \n",
    "        return\n",
    "    #homework 3 inspired validation data spilt function\n",
    "    def split(self, ratio = .8 ):\n",
    "        index = int(ratio*self.length)\n",
    "        \n",
    "        split,self.test_set = split_dict(self.test_set, index)\n",
    "        \n",
    "        self.set_labels = self.set_labels[:index]\n",
    "        self.set_text = self.set_text[:index]\n",
    "        self.length = len(self.test_set)\n",
    "        \n",
    "        return split\n",
    "    #functions required by pytorch for handling data\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return {'text': self.set_text[index], 'label': self.set_labels[index]}\n",
    "    \n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primary dataset classes for handling data and loading it into pytorch. Code written to be reuseable, allowing for easy testing of different models\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' tokenizer class to allow easy swapping of tokenizers\n",
    "params: use_tokenizer is the tokenizer function of choice\n",
    "max: the maxiumum sequence length. tokenizer truncates based off this'''\n",
    "\n",
    "class _tokenize(object):\n",
    "    def __init__(self,  use_tokenizer, max=512):\n",
    "         self.use_tokenizer = use_tokenizer\n",
    "         self.max_sequence_len =max\n",
    "    #basically just calls the tokenizer, returning embeddings  dict    \n",
    "    def __call__(self, data):\n",
    "        text= [x['text'] for x in data]\n",
    "        label = [x ['label'] for x in data]\n",
    "        \n",
    "        \n",
    "        embeddings = self.use_tokenizer(text=text, return_tensors = \"pt\", padding = True, truncation= True, max_length = self.max_sequence_len)\n",
    "        embeddings.update({'labels' : torch.tensor(label)})\n",
    "        return embeddings\n",
    "#helper to solve for accuracy, true pos, true neg, false pos, false neg\n",
    "# takes in the actual labels and a series of predictions\n",
    "#outputs array of stats\n",
    "def calculate_stats(labels, predictions):\n",
    "    acc = 0.0\n",
    "    fp =0.0\n",
    "    fn = 0.0\n",
    "    tp =0.0\n",
    "    tn = 0.0\n",
    "    size = len(labels)\n",
    "    counter = 0\n",
    "    \n",
    "    for x in labels:\n",
    "        if x == 1 and predictions[counter] == 1:\n",
    "            tp+=1\n",
    "            acc +=1\n",
    "        elif x == 0 and predictions[counter] == 0:\n",
    "            tn+=1\n",
    "            acc+=1\n",
    "        elif x == 1:\n",
    "            fp  +=1\n",
    "        elif x == 0:\n",
    "            fn +=1 \n",
    "        counter +=1\n",
    "            \n",
    "    return [acc/size, tp/size, tn/size, fp/size, fn/size]\n",
    "#evaluates the model \n",
    "def test (model, data, device, ):\n",
    "    print (\"Evaluating\")\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    predictions = []\n",
    "    labels= []\n",
    "   \n",
    "    model.eval()\n",
    "    for batch in tqdm (data, total=len(data)):\n",
    "        labels += batch['labels'].numpy().flatten().tolist()\n",
    "\n",
    "        batch = {i:j.type(torch.long).to(device) for i,j in batch.items()}\n",
    "        with torch.no_grad():\n",
    "\n",
    "           \n",
    "            model_out = model(**batch)\n",
    "            loss,logits =model_out[:2]\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "            logits = logits.detach().cpu().numpy() \n",
    "        \n",
    "            predictions  += logits.argmax(axis = -1).flatten().tolist()\n",
    "    total_loss = total_loss/len(data)\n",
    "    \n",
    "  \n",
    "    stats= calculate_stats (labels, predictions)        \n",
    "       \n",
    "    return total_loss, stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizer class and helpers for our training loop + eval function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Training loop  \n",
    "Params: model, data (your training data), valid (your valid data), optimizer, scheduler, device, epochs'''\n",
    "\n",
    "\n",
    "\n",
    "def train(model, data, valid, optimizer, scheduler, device, epochs=1):\n",
    "    \n",
    "  \n",
    "    avg_loss_per_epoch = list ()\n",
    "    acc_t = []\n",
    "    tp_t = []\n",
    "    tn_t = []\n",
    "    fp_t = []\n",
    "    fn_t = []\n",
    "    \n",
    "    acc_v = []\n",
    "    tp_v = []\n",
    "    tn_v = []\n",
    "    fp_v = []\n",
    "    fn_v = []\n",
    "    \n",
    "    v_loss_t = list ()\n",
    "    for i in range(epochs):\n",
    "        print (\"Training \" ,i, \" Epoch\")\n",
    "        total_loss = 0\n",
    "        predictions = []\n",
    "        labels = []\n",
    "        v_loss = []\n",
    "        model.train()\n",
    "        for batch in tqdm (data, total=len(data)):\n",
    "            labels += batch['labels'].numpy().flatten().tolist()\n",
    "            batch = {i:j.type(torch.long).to(device) for i,j in batch.items()}\n",
    "\n",
    "            model.zero_grad()\n",
    "        \n",
    "        \n",
    "            model_out = model(**batch)\n",
    "        \n",
    "            loss_obj, logits = model_out[:2]\n",
    "    \n",
    "        \n",
    "            total_loss += loss_obj.item()\n",
    "        \n",
    "            loss_obj.backward()\n",
    "        \n",
    "        \n",
    "        \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            \n",
    "            logits = logits.detach().cpu().numpy()\n",
    "        \n",
    "            predictions  += logits.argmax(axis = -1).flatten().tolist()\n",
    "  \n",
    "        stats= calculate_stats (labels, predictions)\n",
    "        \n",
    "        avg_loss_per_epoch.append(total_loss/len(data))\n",
    "        \n",
    "        print (\"training accuracy for epoch \", i ,\": \", stats[0])\n",
    "        print (\"training loss for epoch \", i ,\": \",total_loss/len(data))\n",
    "        acc_t.append(stats[0])\n",
    "        tp_t.append(stats[1])\n",
    "        tn_t.append(stats[2])\n",
    "        fp_t.append(stats[3])\n",
    "        fn_t.append(stats[4])\n",
    "        \n",
    "  \n",
    "        v_loss, stats_v = test(model, valid, device)\n",
    "        \n",
    "        \n",
    "        \n",
    "        acc_v.append(stats_v[0])\n",
    "        tp_v.append(stats_v[1])\n",
    "        tn_v.append(stats_v[2])\n",
    "        fp_v.append(stats_v[3])\n",
    "        fn_v.append(stats_v[4])\n",
    "        \n",
    "        v_loss_t.append(v_loss)\n",
    "        \n",
    "        print (\"eval accuracy for epoch \", i ,\": \",stats_v[0])\n",
    "        print (\"eval loss for epoch \", i ,\": \",v_loss)\n",
    "      \n",
    "    t_stats = [avg_loss_per_epoch, acc_t, tp_t, tn_t, fp_t, fn_t]\n",
    "    v_stats = [v_loss_t, acc_v, tp_v, tn_v, fp_v, fn_v]\n",
    "    return  t_stats, v_stats\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at distilgpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tokenzier = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\\ngpt2 = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\\n\\ngpt2.to(device)\\nprint (device,\"being_used\")\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = 'distilgpt2'\n",
    "config = GPT2Config.from_pretrained(pretrained_model_name_or_path = model, num_labels =2, fp16 = True, num_workers = 4)\n",
    "tokenzier = GPT2Tokenizer.from_pretrained(pretrained_model_name_or_path = model)\n",
    "tokenzier.padding_side = \"left\"\n",
    "tokenzier.pad_token = '50256'\n",
    "gpt2 = GPT2ForSequenceClassification.from_pretrained(pretrained_model_name_or_path = model, config = config )\n",
    "gpt2.resize_token_embeddings(len(tokenzier))\n",
    "gpt2.config.pad_token_id = gpt2.config.eos_token_id\n",
    "gpt2.to(device)\n",
    "\n",
    "'''tokenzier = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "gpt2 = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "\n",
    "gpt2.to(device)\n",
    "print (device,\"being_used\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inializing our first model, gpt2. gpt2 is a decoder based transformer, which makes it superior at text generation, but generally worse at classification tasks. I used distilgpt2, as gpt2-medium was 500mb too large for my gpus memory. Feel free to go up in complexity if you can run it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "baby_spam_test = Datasets(testpath='../datasets/SpamHam/test.csv' ,Emails=True, size = 2000)\n",
    "baby_spam_train = Datasets(testpath='../datasets/SpamHam/train.csv' ,Emails=True, size = 2000)\n",
    "baby_spam_valid = Datasets(final_data = baby_spam_train.split(), data_processed=True)\n",
    "gpt_tokenizer = _tokenize(tokenzier)\n",
    "\n",
    "baby_spam_train_dataloader = DataLoader(baby_spam_train, batch_size= 8, shuffle=True, collate_fn = gpt_tokenizer)\n",
    "baby_spam_valid_dataloader = DataLoader(baby_spam_valid, batch_size=8, shuffle=False, collate_fn = gpt_tokenizer)\n",
    "baby_spam_test_dataloader =  DataLoader(baby_spam_test, batch_size= 8, shuffle=False, collate_fn= gpt_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using a baby dataset for the inital comparisions between the models. Batch size is 'only' 8, as that was the highest I could go without graident checkpointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  0  Epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:58<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy for epoch  0 :  0.6625\n",
      "training loss for epoch  0 :  0.7041607058048248\n",
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:05<00:00,  9.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval accuracy for epoch  0 :  0.7625\n",
      "eval loss for epoch  0 :  0.5020402929186821\n",
      "Training  1  Epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:55<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy for epoch  1 :  0.73625\n",
      "training loss for epoch  1 :  0.5386661452800036\n",
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:05<00:00,  9.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval accuracy for epoch  1 :  0.7625\n",
      "eval loss for epoch  1 :  0.5020402929186821\n",
      "Training  2  Epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:58<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy for epoch  2 :  0.74\n",
      "training loss for epoch  2 :  0.5304337309300899\n",
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:05<00:00,  9.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval accuracy for epoch  2 :  0.7625\n",
      "eval loss for epoch  2 :  0.5020402929186821\n",
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:26<00:00,  9.57it/s]\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(gpt2.parameters(), lr= 2e-5, eps = 1e-8)\n",
    "steps = len(baby_spam_train_dataloader)\n",
    "scheduler = transformers.get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0 , num_training_steps = steps)\n",
    "\n",
    "predictions, loss = train(gpt2, baby_spam_train_dataloader, baby_spam_valid_dataloader, optimizer, scheduler, device,3)\n",
    "\n",
    "v_loss, stats_test = test(gpt2, baby_spam_test_dataloader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training printouts. eval is broken for some reason, only records the first evaluation and loss. Final printouts from the test set are below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.772\n",
      "True pos 0.3605\n",
      "True neg 0.4115\n",
      "False pos 0.114\n",
      "False neg 0.114\n"
     ]
    }
   ],
   "source": [
    "print (\"acc:\", stats_test[0])\n",
    "print (\"True pos\", stats_test[1])\n",
    "print (\"True neg\", stats_test[2])\n",
    "print (\"False pos\", stats_test[3])\n",
    "print (\"False neg\", stats_test[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT2 delivers a respectable test set average on the babyset. accuracies in the 70ish % range with a 10-20% false positive rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "baby_phish_test = Datasets('../datasets/PhishingURLs/test.csv' ,Emails=False, size=2000)\n",
    "baby_phish_train = Datasets('../datasets/PhishingURLs/train.csv' ,Emails=False, size=2000)\n",
    "baby_phish_valid = Datasets(final_data = baby_phish_train.split(), data_processed=True)\n",
    "\n",
    "baby_phish_train_dataloader = DataLoader(baby_phish_train, batch_size= 8, shuffle=True, collate_fn = gpt_tokenizer)\n",
    "baby_phish_valid_dataloader = DataLoader(baby_phish_valid, batch_size=8, shuffle=False, collate_fn = gpt_tokenizer)\n",
    "baby_phish_test_dataloader =  DataLoader(baby_phish_test, batch_size=8, shuffle=False, collate_fn= gpt_tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "phising datasets now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  0  Epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:13<00:00, 15.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy for epoch  0 :  0.7425\n",
      "training loss for epoch  0 :  0.5332708093523979\n",
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 57.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval accuracy for epoch  0 :  0.8\n",
      "eval loss for epoch  0 :  0.3839166308939457\n",
      "Training  1  Epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:12<00:00, 15.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy for epoch  1 :  0.81125\n",
      "training loss for epoch  1 :  0.40501326840370894\n",
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 57.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval accuracy for epoch  1 :  0.8\n",
      "eval loss for epoch  1 :  0.3839166308939457\n",
      "Training  2  Epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:13<00:00, 15.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy for epoch  2 :  0.803125\n",
      "training loss for epoch  2 :  0.4107826388441026\n",
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 63.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval accuracy for epoch  2 :  0.8\n",
      "eval loss for epoch  2 :  0.3839166308939457\n",
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:03<00:00, 63.77it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(gpt2.parameters(), lr= 2e-5, eps = 1e-8)\n",
    "steps = len(baby_phish_train_dataloader)\n",
    "scheduler = transformers.get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0 , num_training_steps = steps)\n",
    "\n",
    "predictions, loss = train(gpt2, baby_phish_train_dataloader, baby_phish_valid_dataloader, optimizer, scheduler, device,3)\n",
    "\n",
    "v_loss, stats_test = test(gpt2, baby_phish_test_dataloader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.806\n",
      "True pos 0.3665\n",
      "True neg 0.4395\n",
      "False pos 0.1265\n",
      "False neg 0.0675\n"
     ]
    }
   ],
   "source": [
    "print (\"acc:\", stats_test[0])\n",
    "print (\"True pos\", stats_test[1])\n",
    "print (\"True neg\", stats_test[2])\n",
    "print (\"False pos\", stats_test[3])\n",
    "print (\"False neg\", stats_test[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar preformance on the phishing baby dataset. 80ish% accuracy with an 10-15% false postive rate depending on the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda being_used\n"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "berto = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "#bert = AutoModelForSequenceClassification.from_pretrained(\"../models\")\n",
    "\n",
    "bert.to(device)\n",
    "\n",
    "print (device,\"being_used\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time for bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bertoken = _tokenize(berto)\n",
    "\n",
    "baby_spam_train_dataloader = DataLoader(baby_spam_train, batch_size= 8, shuffle=True, collate_fn = bertoken)\n",
    "baby_spam_valid_dataloader = DataLoader(baby_spam_valid, batch_size=8, shuffle=False, collate_fn = bertoken)\n",
    "baby_spam_test_dataloader =  DataLoader(baby_spam_test, batch_size= 8, shuffle=False, collate_fn= bertoken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  0  Epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:30<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy for epoch  0 :  0.880625\n",
      "training loss for epoch  0 :  0.30530863113701345\n",
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:08<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval accuracy for epoch  0 :  0.9225\n",
      "eval loss for epoch  0 :  0.23091262377798558\n",
      "Training  1  Epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:35<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy for epoch  1 :  0.960625\n",
      "training loss for epoch  1 :  0.12769196196459234\n",
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:08<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval accuracy for epoch  1 :  0.9225\n",
      "eval loss for epoch  1 :  0.23091262377798558\n",
      "Training  2  Epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:37<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy for epoch  2 :  0.961875\n",
      "training loss for epoch  2 :  0.1259345064871013\n",
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:08<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval accuracy for epoch  2 :  0.9225\n",
      "eval loss for epoch  2 :  0.23091262377798558\n",
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:41<00:00,  6.08it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = torch.optim.AdamW(bert.parameters(), lr= 2e-5, eps = 1e-8)\n",
    "steps = len(baby_spam_train_dataloader)\n",
    "scheduler = transformers.get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0 , num_training_steps = steps)\n",
    "\n",
    "predictions, loss = train(bert, baby_spam_train_dataloader, baby_spam_valid_dataloader, optimizer, scheduler, device,3)\n",
    "\n",
    "v_loss, stats_test = test(bert, baby_spam_test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.927\n",
      "True pos 0.422\n",
      "True neg 0.505\n",
      "False pos 0.0525\n",
      "False neg 0.0205\n"
     ]
    }
   ],
   "source": [
    "print (\"acc:\", stats_test[0])\n",
    "print (\"True pos\", stats_test[1])\n",
    "print (\"True neg\", stats_test[2])\n",
    "print (\"False pos\", stats_test[3])\n",
    "print (\"False neg\", stats_test[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bert blows gpt2 out of the water with a 92ish% acc and a 5% false postive rate depending on the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby_phish_train_dataloader = DataLoader(baby_phish_train, batch_size= 8, shuffle=True, collate_fn = bertoken)\n",
    "baby_phish_valid_dataloader = DataLoader(baby_phish_valid, batch_size=8, shuffle=False, collate_fn = bertoken)\n",
    "baby_phish_test_dataloader =  DataLoader(baby_phish_test, batch_size=8, shuffle=False, collate_fn= bertoken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for phishing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  0  Epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:19<00:00, 10.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy for epoch  0 :  0.83875\n",
      "training loss for epoch  0 :  0.40409577967599036\n",
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:07<00:00,  6.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval accuracy for epoch  0 :  0.8675\n",
      "eval loss for epoch  0 :  0.34582294009625913\n",
      "Training  1  Epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:19<00:00, 10.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy for epoch  1 :  0.90625\n",
      "training loss for epoch  1 :  0.24591078142635525\n",
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:08<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval accuracy for epoch  1 :  0.8675\n",
      "eval loss for epoch  1 :  0.34582294009625913\n",
      "Training  2  Epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:19<00:00, 10.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy for epoch  2 :  0.9075\n",
      "training loss for epoch  2 :  0.23976982810534536\n",
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:08<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval accuracy for epoch  2 :  0.8675\n",
      "eval loss for epoch  2 :  0.34582294009625913\n",
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:07<00:00, 35.08it/s]\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(bert.parameters(), lr= 2e-5, eps = 1e-8)\n",
    "steps = len(baby_phish_train_dataloader)\n",
    "scheduler = transformers.get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0 , num_training_steps = steps)\n",
    "\n",
    "predictions, loss = train(bert, baby_phish_train_dataloader, baby_spam_valid_dataloader, optimizer, scheduler, device,3)\n",
    "\n",
    "v_loss, stats_test = test(bert, baby_phish_test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8845\n",
      "True pos 0.4105\n",
      "True neg 0.474\n",
      "False pos 0.0825\n",
      "False neg 0.033\n"
     ]
    }
   ],
   "source": [
    "print (\"acc:\", stats_test[0])\n",
    "print (\"True pos\", stats_test[1])\n",
    "print (\"True neg\", stats_test[2])\n",
    "print (\"False pos\", stats_test[3])\n",
    "print (\"False neg\", stats_test[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another strong preformance by bert, with a 88-90% acc and a 5-8% false postive rate depending on the run. Conclusion: Bert is by far the better model when compared with a slighter smaller sized GPT-2 model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have found the best preforming model, lets try a run with the fulldatasets. Note: outputs were accidentally cleared for spam training, and re-running them would take hours. However, there are printouts at the bottom of the notebook with the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spam_test = Datasets(testpath='../datasets/SpamHam/test.csv' ,Emails=True)\n",
    "spam_train = Datasets(testpath='../datasets/SpamHam/train.csv' ,Emails=True)\n",
    "spam_valid = Datasets(final_data = spam_train.split(), data_processed=True)\n",
    "\n",
    "\n",
    "spam_train_dataloader = DataLoader(spam_train, batch_size= 8, shuffle=True, collate_fn = bertoken)\n",
    "spam_valid_dataloader = DataLoader(spam_valid, batch_size=8, shuffle=False, collate_fn = bertoken)\n",
    "spam_test_dataloader =  DataLoader(spam_test, batch_size= 8, shuffle=False, collate_fn= bertoken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(bert.parameters(), lr= 2e-5, eps = 1e-8)\n",
    "steps = len(spam_train_dataloader)\n",
    "scheduler = transformers.get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0 , num_training_steps = steps)\n",
    "\n",
    "predictions, loss = train(bert, spam_train_dataloader, spam_valid_dataloader, optimizer, scheduler, device,3)\n",
    "\n",
    "v_loss, stats_test = test(bert, spam_test_dataloader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving a checkpoint of the model, as training took forever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert.save_pretrained('../models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertoken = _tokenize(berto)\n",
    "phish_test = Datasets('..datasets//PhishingURLs/test.csv' ,False)\n",
    "phish_train = Datasets('../datasets/PhishingURLs/train.csv' ,False)\n",
    "phish_valid = Datasets(final_data = phish_train.split(), data_processed=True)\n",
    "\n",
    "phish_train_dataloader = DataLoader(phish_train, batch_size= 4, shuffle=True, collate_fn = bertoken)\n",
    "phish_valid_dataloader = DataLoader(phish_valid, batch_size=4, shuffle=False, collate_fn = bertoken)\n",
    "phish_test_dataloader =  DataLoader(phish_test, batch_size=4, shuffle=False, collate_fn= bertoken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time for phishing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  0  Epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128000/128000 [2:33:06<00:00, 13.93it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy for epoch  0 :  0.9719843202818755\n",
      "training loss for epoch  0 :  0.13220235812806158\n",
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32000/32000 [08:43<00:00, 61.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval accuracy for epoch  0 :  0.981859375\n",
      "eval loss for epoch  0 :  0.09004282037388169\n",
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40000/40000 [10:52<00:00, 61.26it/s]\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(bert.parameters(), lr= 2e-5, eps = 1e-8)\n",
    "steps = len(phish_train_dataloader)\n",
    "scheduler = transformers.get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0 , num_training_steps = steps)\n",
    "\n",
    "predictions, loss = train(bert, phish_train_dataloader,  phish_valid_dataloader, optimizer, scheduler, device,1)\n",
    "\n",
    "v_loss, stats_test = test(bert, phish_test_dataloader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very strong results on the full phishing dataset by bert, but also incredibly slow training times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.98195625\n",
      "True pos 0.4890125\n",
      "True neg 0.49294375\n",
      "False pos 0.0109875\n",
      "False neg 0.00705625\n"
     ]
    }
   ],
   "source": [
    "print (\"acc:\", stats_test[0])\n",
    "print (\"True pos\", stats_test[1])\n",
    "print (\"True neg\", stats_test[2])\n",
    "print (\"False pos\", stats_test[3])\n",
    "print (\"False neg\", stats_test[4])\n",
    "\n",
    "\n",
    "for i in range (len(stats_test)):\n",
    "    stats_test[i] = stats_test[i]*len(phish_test_dataloader)\n",
    "    \n",
    "precision = stats_test[2]/(stats_test[2]+ stats_test[4])\n",
    "recall = stats_test[2]/ (stats_test[2]+ stats_test[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7266/7266 [20:26<00:00,  5.93it/s]\n"
     ]
    }
   ],
   "source": [
    "#torch.cuda.empty_cache()\n",
    "#berto = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# bert = AutoModelForSequenceClassification.from_pretrained(\"../models\")\n",
    "# bert.to(device)\n",
    "v_loss, stats_test = test(bert, spam_test_dataloader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the bert finetune test set printouts. The training printouts were accidentally cleared, but the model was saved before outputs cleared and testing was re-run.  Note: if you want to load the model checkpoint for spam, place \"models\" in the root, and uncomment out the commented code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9882664647993944\n",
      "True pos 0.4675349253320487\n",
      "True neg 0.5207315394673456\n",
      "False pos 0.009152845640355104\n",
      "False neg 0.002580689560250499\n",
      "0.9888591217982228\n"
     ]
    }
   ],
   "source": [
    "print (\"acc:\", stats_test[0])\n",
    "print (\"True pos\", stats_test[1])\n",
    "print (\"True neg\", stats_test[2])\n",
    "print (\"False pos\", stats_test[3])\n",
    "print (\"False neg\", stats_test[4])\n",
    "\n",
    "\n",
    "\n",
    "for i in range (len(stats_test)):\n",
    "    stats_test[i] = stats_test[i]*len(spam_test_dataloader)\n",
    "    \n",
    "precision = stats_test[2]/(stats_test[2]+ stats_test[4])\n",
    "recall = stats_test[2]/ (stats_test[2]+ stats_test[3])\n",
    "fone= (2*precision*recall)/(precision+recall)\n",
    "print (fone)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
