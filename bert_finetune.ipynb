{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-2 and Bert finetuning comparisions\n",
    "\n",
    "\n",
    "Aaron Semones\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy \n",
    "import os \n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import io\n",
    "import transformers\n",
    "from tqdm import tqdm\n",
    "from transformers import GPT2Config, GPT2ForSequenceClassification, GPT2Tokenizer, AutoTokenizer,  AutoModelForSequenceClassification\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libaries \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    " # formatting function for phishing dataset\n",
    "def remove_doublequotes(file_dir): # \n",
    "    raw_file_str = ''\n",
    "    with open(file_dir, 'r', encoding='utf-8') as f:\n",
    "        raw_file_str = f.read().replace('\"\"', '\"')\n",
    "    with open(file_dir, 'w', encoding='utf-8') as f:\n",
    "        f.write(raw_file_str)\n",
    "        \n",
    "#partition a dictionary\n",
    "def split_dict (dict1, index):\n",
    "    dict1c = dict1\n",
    "    dict1 = dict(list(dict1c.items())[index:])\n",
    "    dict2 = dict(list(dict1c.items())[:index])\n",
    "    return dict1, dict2\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Misc. helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") #sets your device. Code will run at a snails pace without gpu\n",
    "\n",
    "\n",
    "\n",
    "class Datasets(Dataset):\n",
    "    def __init__ (self, testpath=None, Emails = None, size =None, final_data = None , data_processed=False): \n",
    "        '''testpath is the path of your csv file, emails is a bool for handling oddities with phising ds\n",
    "        size is the desired num_entries, final_data is for turning already pre-processed data into a dataset for loading (ie validiation set),\n",
    "        dataprocessed is the bool controlling that functionalty\n",
    "        \n",
    "        \n",
    "        Members:\n",
    "        \n",
    "        length is number of examples\n",
    "        test_set is a dict of the entire set\n",
    "        set_labels is a list of the labels\n",
    "        set_text is a list of the text\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        if (data_processed):\n",
    "            self.length = len(final_data)\n",
    "            self.test_set = final_data\n",
    "            self.set_labels = [self.test_set[x] for x in self.test_set]\n",
    "            self.set_text = list (self.test_set.keys())\n",
    "            return\n",
    "        \n",
    "        if Emails == False:\n",
    "            remove_doublequotes(testpath)\n",
    "        \n",
    "        \n",
    "        if (size):\n",
    "            self.test_set = pd.read_csv(testpath, nrows = size)\n",
    "        else: \n",
    "            self.test_set = pd.read_csv(testpath)\n",
    " \n",
    "        if (Emails == True):\n",
    "            self.test_set = self.test_set.set_index('text')['label'].to_dict()\n",
    "        \n",
    "        else:\n",
    "            self.test_set['label'] = self.test_set ['label'].apply(lambda x : 2 - x)\n",
    "            print(self.test_set.head())\n",
    "            self.test_set =  self.test_set.set_index('text')['label'].to_dict() \n",
    "            \n",
    "        self.length = len (self.test_set)\n",
    "        \n",
    "        self.set_labels = [self.test_set[x] for x in self.test_set]\n",
    "        self.set_text = list (self.test_set.keys())\n",
    "        \n",
    "        return\n",
    "    #homework 3 inspired validation data spilt function\n",
    "    def split(self, ratio = .8 ):\n",
    "        index = int(ratio*self.length)\n",
    "        \n",
    "        split,self.test_set = split_dict(self.test_set, index)\n",
    "        \n",
    "        self.set_labels = self.set_labels[:index]\n",
    "        self.set_text = self.set_text[:index]\n",
    "        self.length = len(self.test_set)\n",
    "        \n",
    "        return split\n",
    "    #functions required by pytorch for handling data\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return {'text': self.set_text[index], 'label': self.set_labels[index]}\n",
    "    \n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primary dataset classes for handling data and loading it into pytorch. Code written to be reuseable, allowing for easy testing of different models\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' tokenizer class to allow easy swapping of tokenizers\n",
    "params: use_tokenizer is the tokenizer function of choice\n",
    "max: the maxiumum sequence length. tokenizer truncates based off this'''\n",
    "\n",
    "class _tokenize(object):\n",
    "    def __init__(self,  use_tokenizer, max=512):\n",
    "         self.use_tokenizer = use_tokenizer\n",
    "         self.max_sequence_len =max\n",
    "    #basically just calls the tokenizer, returning embeddings  dict    \n",
    "    def __call__(self, data):\n",
    "        text= [x['text'] for x in data]\n",
    "        label = [x ['label'] for x in data]\n",
    "        \n",
    "        \n",
    "        embeddings = self.use_tokenizer(text=text, return_tensors = \"pt\", padding = True, truncation= True, max_length = self.max_sequence_len)\n",
    "        embeddings.update({'labels' : torch.tensor(label)})\n",
    "        return embeddings\n",
    "#helper to solve for accuracy, true pos, true neg, false pos, false neg\n",
    "# takes in the actual labels and a series of predictions\n",
    "#outputs array of stats\n",
    "def calculate_stats(labels, predictions):\n",
    "    acc = 0.0\n",
    "    fp =0.0\n",
    "    fn = 0.0\n",
    "    tp =0.0\n",
    "    tn = 0.0\n",
    "    size = len(labels)\n",
    "    counter = 0\n",
    "    \n",
    "    for x in labels:\n",
    "        if x == 1 and predictions[counter] == 1:\n",
    "            tp+=1\n",
    "            acc +=1\n",
    "        elif x == 0 and predictions[counter] == 0:\n",
    "            tn+=1\n",
    "            acc+=1\n",
    "        elif x == 1:\n",
    "            fp  +=1\n",
    "        elif x == 0:\n",
    "            fn +=1 \n",
    "        counter +=1\n",
    "            \n",
    "    return [acc/size, tp/size, tn/size, fp/size, fn/size]\n",
    "#evaluates the model \n",
    "def test (model, data, device, ):\n",
    "    print (\"Evaluating\")\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    predictions = []\n",
    "    labels= []\n",
    "   \n",
    "    model.eval()\n",
    "    for batch in tqdm (data, total=len(data)):\n",
    "        labels += batch['labels'].numpy().flatten().tolist()\n",
    "\n",
    "        batch = {i:j.type(torch.long).to(device) for i,j in batch.items()}\n",
    "        with torch.no_grad():\n",
    "\n",
    "           \n",
    "            model_out = model(**batch)\n",
    "            loss,logits =model_out[:2]\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "            logits = logits.detach().cpu().numpy() \n",
    "        \n",
    "            predictions  += logits.argmax(axis = -1).flatten().tolist()\n",
    "    total_loss = total_loss/len(data)\n",
    "    \n",
    "  \n",
    "    stats= calculate_stats (labels, predictions)        \n",
    "       \n",
    "    return total_loss, stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizer class and helpers for our training loop + eval function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Training loop  \n",
    "Params: model, data (your training data), valid (your valid data), optimizer, scheduler, device, epochs'''\n",
    "\n",
    "\n",
    "\n",
    "def train(model, data, valid, optimizer, scheduler, device, epochs=1):\n",
    "    \n",
    "  \n",
    "    avg_loss_per_epoch = list ()\n",
    "    acc_t = []\n",
    "    tp_t = []\n",
    "    tn_t = []\n",
    "    fp_t = []\n",
    "    fn_t = []\n",
    "    \n",
    "    acc_v = []\n",
    "    tp_v = []\n",
    "    tn_v = []\n",
    "    fp_v = []\n",
    "    fn_v = []\n",
    "    \n",
    "    v_loss_t = list ()\n",
    "    for i in range(epochs):\n",
    "        print (\"Training \" ,i, \" Epoch\")\n",
    "        total_loss = 0\n",
    "        predictions = []\n",
    "        labels = []\n",
    "        v_loss = []\n",
    "        model.train()\n",
    "        for batch in tqdm (data, total=len(data)):\n",
    "            labels += batch['labels'].numpy().flatten().tolist()\n",
    "            batch = {i:j.type(torch.long).to(device) for i,j in batch.items()}\n",
    "\n",
    "            model.zero_grad()\n",
    "        \n",
    "        \n",
    "            model_out = model(**batch)\n",
    "        \n",
    "            loss_obj, logits = model_out[:2]\n",
    "    \n",
    "        \n",
    "            total_loss += loss_obj.item()\n",
    "        \n",
    "            loss_obj.backward()\n",
    "        \n",
    "        \n",
    "        \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            \n",
    "            logits = logits.detach().cpu().numpy()\n",
    "        \n",
    "            predictions  += logits.argmax(axis = -1).flatten().tolist()\n",
    "  \n",
    "        stats= calculate_stats (labels, predictions)\n",
    "        \n",
    "        avg_loss_per_epoch.append(total_loss/len(data))\n",
    "        \n",
    "        print (\"training accuracy for epoch \", i ,\": \", stats[0])\n",
    "        print (\"training loss for epoch \", i ,\": \",total_loss/len(data))\n",
    "        acc_t.append(stats[0])\n",
    "        tp_t.append(stats[1])\n",
    "        tn_t.append(stats[2])\n",
    "        fp_t.append(stats[3])\n",
    "        fn_t.append(stats[4])\n",
    "        \n",
    "  \n",
    "        v_loss, stats_v = test(model, valid, device)\n",
    "        \n",
    "        \n",
    "        \n",
    "        acc_v.append(stats_v[0])\n",
    "        tp_v.append(stats_v[1])\n",
    "        tn_v.append(stats_v[2])\n",
    "        fp_v.append(stats_v[3])\n",
    "        fn_v.append(stats_v[4])\n",
    "        \n",
    "        v_loss_t.append(v_loss)\n",
    "        \n",
    "        print (\"eval accuracy for epoch \", i ,\": \",stats_v[0])\n",
    "        print (\"eval loss for epoch \", i ,\": \",v_loss)\n",
    "      \n",
    "    t_stats = [avg_loss_per_epoch, acc_t, tp_t, tn_t, fp_t, fn_t]\n",
    "    v_stats = [v_loss_t, acc_v, tp_v, tn_v, fp_v, fn_v]\n",
    "    return  t_stats, v_stats\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at distilgpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tokenzier = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\\ngpt2 = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\\n\\ngpt2.to(device)\\nprint (device,\"being_used\")\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = 'distilgpt2'\n",
    "config = GPT2Config.from_pretrained(pretrained_model_name_or_path = model, num_labels =2, fp16 = True, num_workers = 4)\n",
    "tokenzier = GPT2Tokenizer.from_pretrained(pretrained_model_name_or_path = model)\n",
    "tokenzier.padding_side = \"left\"\n",
    "tokenzier.pad_token = '50256'\n",
    "gpt2 = GPT2ForSequenceClassification.from_pretrained(pretrained_model_name_or_path = model, config = config )\n",
    "gpt2.resize_token_embeddings(len(tokenzier))\n",
    "gpt2.config.pad_token_id = gpt2.config.eos_token_id\n",
    "gpt2.to(device)\n",
    "\n",
    "'''tokenzier = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "gpt2 = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "\n",
    "gpt2.to(device)\n",
    "print (device,\"being_used\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inializing our first model, gpt2. gpt2 is a decoder based transformer, which makes it superior at text generation, but generally worse at classification tasks. I used distilgpt2, as gpt2-medium was 500mb too large for my gpus memory. Feel free to go up in complexity if you can run it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby_spam_test = Datasets(testpath='./datasets/SpamHam/test.csv' ,Emails=True, size = 2000)\n",
    "baby_spam_train = Datasets(testpath='./datasets/SpamHam/train.csv' ,Emails=True, size = 2000)\n",
    "baby_spam_valid = Datasets(final_data = baby_spam_train.split(), data_processed=True)\n",
    "gpt_tokenizer = _tokenize(tokenzier)\n",
    "\n",
    "baby_spam_train_dataloader = DataLoader(baby_spam_train, batch_size= 8, shuffle=True, collate_fn = gpt_tokenizer)\n",
    "baby_spam_valid_dataloader = DataLoader(baby_spam_valid, batch_size=8, shuffle=False, collate_fn = gpt_tokenizer)\n",
    "baby_spam_test_dataloader =  DataLoader(baby_spam_test, batch_size= 8, shuffle=False, collate_fn= gpt_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using a baby dataset for the inital comparisions between the models. Batch size is 'only' 8, as that was the highest I could go without graident checkpointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  0  Epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:57<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy for epoch  0 :  0.690625\n",
      "training loss for epoch  0 :  0.5926605705916882\n",
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:05<00:00,  9.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval accuracy for epoch  0 :  0.765\n",
      "eval loss for epoch  0 :  0.5058020314574242\n",
      "Training  1  Epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:57<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy for epoch  1 :  0.766875\n",
      "training loss for epoch  1 :  0.49623864896595477\n",
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:05<00:00,  9.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval accuracy for epoch  1 :  0.765\n",
      "eval loss for epoch  1 :  0.5058020314574242\n",
      "Training  2  Epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:58<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy for epoch  2 :  0.768125\n",
      "training loss for epoch  2 :  0.49269786052405834\n",
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:05<00:00,  9.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval accuracy for epoch  2 :  0.765\n",
      "eval loss for epoch  2 :  0.5058020314574242\n",
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:25<00:00,  9.70it/s]\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(gpt2.parameters(), lr= 2e-5, eps = 1e-8)\n",
    "steps = len(baby_spam_train_dataloader)\n",
    "scheduler = transformers.get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0 , num_training_steps = steps)\n",
    "\n",
    "predictions, loss = train(gpt2, baby_spam_train_dataloader, baby_spam_valid_dataloader, optimizer, scheduler, device,3)\n",
    "\n",
    "v_loss, stats_test = test(gpt2, baby_spam_test_dataloader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training printouts. eval is broken for some reason, only records the first evaluation and loss. Final printouts from the test set are below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.7575\n",
      "True pos 0.266\n",
      "True neg 0.4915\n",
      "False pos 0.2085\n",
      "False neg 0.034\n"
     ]
    }
   ],
   "source": [
    "print (\"acc:\", stats_test[0])\n",
    "print (\"True pos\", stats_test[1])\n",
    "print (\"True neg\", stats_test[2])\n",
    "print (\"False pos\", stats_test[3])\n",
    "print (\"False neg\", stats_test[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT2 delivers a respectable test set average on the babyset. 75% accuracy with a 20% false positive rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                               text\n",
      "0      0                       http://minsotc.alania.gov.ru\n",
      "1      0                       http://www.freejavaguide.com\n",
      "2      1  http://yeneliswa.co.za/moods/bankofamerica/7dd...\n",
      "3      0  https://victordahdalehfoundation.com/programme...\n",
      "4      0          http://camphhsi.com/product/list_947.html\n",
      "   label                                               text\n",
      "0      0                        https://blog.sockpuppet.us/\n",
      "1      0                  https://blog.apiki.com/seguranca/\n",
      "2      1  http://autoecole-lauriston.com/a/T0RVd056QXlNe...\n",
      "3      1  http://chinpay.site/index.html?hgcFSE@E$Z*DFcG...\n",
      "4      0  http://www.firstfivenebraska.org/blog/article/...\n"
     ]
    }
   ],
   "source": [
    "baby_phish_test = Datasets('./datasets/PhishingURLs/test.csv' ,False, size=2000)\n",
    "baby_phish_train = Datasets('./datasets/PhishingURLs/train.csv' ,False, size=2000)\n",
    "baby_phish_valid = Datasets(final_data = baby_phish_train.split(), data_processed=True)\n",
    "\n",
    "baby_phish_train_dataloader = DataLoader(baby_phish_train, batch_size= 8, shuffle=True, collate_fn = gpt_tokenizer)\n",
    "baby_phish_valid_dataloader = DataLoader(baby_phish_valid, batch_size=8, shuffle=False, collate_fn = gpt_tokenizer)\n",
    "baby_phish_test_dataloader =  DataLoader(baby_phish_test, batch_size=8, shuffle=False, collate_fn= gpt_tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "phising datasets now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "Training  0  Epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(steps)\n\u001b[0;32m      4\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m transformers\u001b[38;5;241m.\u001b[39mget_linear_schedule_with_warmup(optimizer, num_warmup_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m , num_training_steps \u001b[38;5;241m=\u001b[39m steps)\n\u001b[1;32m----> 6\u001b[0m predictions, loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgpt2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaby_phish_train_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaby_phish_valid_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m v_loss, stats_test \u001b[38;5;241m=\u001b[39m test(gpt2, baby_phish_test_dataloader, device)\n",
      "Cell \u001b[1;32mIn[44], line 50\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, data, valid, optimizer, scheduler, device, epochs)\u001b[0m\n\u001b[0;32m     44\u001b[0m loss_obj\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     48\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m---> 50\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     54\u001b[0m logits \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:75\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     74\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\optim\\optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    383\u001b[0m             )\n\u001b[1;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\optim\\adamw.py:159\u001b[0m, in \u001b[0;36mAdamW.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;129m@_use_grad_for_differentiable\u001b[39m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, closure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    153\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform a single optimization step.\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \n\u001b[0;32m    155\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03m        closure (Callable, optional): A closure that reevaluates the model\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m            and returns the loss.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 159\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_graph_capture_health_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\optim\\optimizer.py:333\u001b[0m, in \u001b[0;36mOptimizer._cuda_graph_capture_health_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cuda_graph_capture_health_check\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;66;03m# Note [torch.compile x capturable]\u001b[39;00m\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;66;03m# If we are compiling, we try to take the capturable path automatically by\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;66;03m# Thus, when compiling, inductor will determine if cudagraphs\u001b[39;00m\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;66;03m# can be enabled based on whether there is input mutation or CPU tensors.\u001b[39;00m\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling() \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_built() \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m--> 333\u001b[0m         capturing \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_current_stream_capturing\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    335\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m capturing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups):\n\u001b[0;32m    336\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting CUDA graph capture of step() for an instance of \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    337\u001b[0m                                \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    338\u001b[0m                                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but param_groups\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m capturable is False.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\cuda\\graphs.py:27\u001b[0m, in \u001b[0;36mis_current_stream_capturing\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_current_stream_capturing\u001b[39m():\n\u001b[0;32m     23\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Return True if CUDA graph capture is underway on the current CUDA stream, False otherwise.\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m    If a CUDA context does not exist on the current device, returns False without initializing the context.\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_cuda_isCurrentStreamCapturing\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(gpt2.parameters(), lr= 2e-5, eps = 1e-8)\n",
    "steps = len(baby_phish_train_dataloader)\n",
    "scheduler = transformers.get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0 , num_training_steps = steps)\n",
    "\n",
    "predictions, loss = train(gpt2, baby_phish_train_dataloader, baby_phish_valid_dataloader, optimizer, scheduler, device,3)\n",
    "\n",
    "v_loss, stats_test = test(gpt2, baby_phish_test_dataloader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.809\n",
      "True pos 0.363\n",
      "True neg 0.446\n",
      "False pos 0.13\n",
      "False neg 0.061\n"
     ]
    }
   ],
   "source": [
    "print (\"acc:\", stats_test[0])\n",
    "print (\"True pos\", stats_test[1])\n",
    "print (\"True neg\", stats_test[2])\n",
    "print (\"False pos\", stats_test[3])\n",
    "print (\"False neg\", stats_test[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar preformance on the phishing baby dataset. 80% accuracy with an 13% false postive rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda being_used\n"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "berto = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "\n",
    "bert.to(device)\n",
    "\n",
    "print (device,\"being_used\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time for bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bertoken = _tokenize(berto)\n",
    "\n",
    "baby_spam_train_dataloader = DataLoader(baby_spam_train, batch_size= 8, shuffle=True, collate_fn = bertoken)\n",
    "baby_spam_valid_dataloader = DataLoader(baby_spam_valid, batch_size=8, shuffle=False, collate_fn = bertoken)\n",
    "baby_spam_test_dataloader =  DataLoader(baby_spam_test, batch_size= 8, shuffle=False, collate_fn= bertoken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  0  Epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:33<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy for epoch  0 :  0.839375\n",
      "training loss for epoch  0 :  0.36200392998754977\n",
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:08<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval accuracy for epoch  0 :  0.9075\n",
      "eval loss for epoch  0 :  0.23575553093105556\n",
      "Training  1  Epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:35<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy for epoch  1 :  0.956875\n",
      "training loss for epoch  1 :  0.13603317678906024\n",
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:08<00:00,  5.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval accuracy for epoch  1 :  0.9075\n",
      "eval loss for epoch  1 :  0.23575553093105556\n",
      "Training  2  Epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:34<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy for epoch  2 :  0.954375\n",
      "training loss for epoch  2 :  0.13723268054425716\n",
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:08<00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval accuracy for epoch  2 :  0.9075\n",
      "eval loss for epoch  2 :  0.23575553093105556\n",
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:40<00:00,  6.12it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = torch.optim.AdamW(bert.parameters(), lr= 2e-5, eps = 1e-8)\n",
    "steps = len(baby_spam_train_dataloader)\n",
    "scheduler = transformers.get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0 , num_training_steps = steps)\n",
    "\n",
    "predictions, loss = train(bert, baby_spam_train_dataloader, baby_spam_valid_dataloader, optimizer, scheduler, device,3)\n",
    "\n",
    "v_loss, stats_test = test(bert, baby_spam_test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9255\n",
      "True pos 0.419\n",
      "True neg 0.5065\n",
      "False pos 0.0555\n",
      "False neg 0.019\n"
     ]
    }
   ],
   "source": [
    "print (\"acc:\", stats_test[0])\n",
    "print (\"True pos\", stats_test[1])\n",
    "print (\"True neg\", stats_test[2])\n",
    "print (\"False pos\", stats_test[3])\n",
    "print (\"False neg\", stats_test[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bert blows gpt2 out of the water with a 92% acc and a 5% false postive rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby_phish_train_dataloader = DataLoader(baby_phish_train, batch_size= 8, shuffle=True, collate_fn = bertoken)\n",
    "baby_phish_valid_dataloader = DataLoader(baby_phish_valid, batch_size=8, shuffle=False, collate_fn = bertoken)\n",
    "baby_phish_test_dataloader =  DataLoader(baby_phish_test, batch_size=8, shuffle=False, collate_fn= bertoken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for phishing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  0  Epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:19<00:00, 10.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy for epoch  0 :  0.831875\n",
      "training loss for epoch  0 :  0.4041268252208829\n",
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:08<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval accuracy for epoch  0 :  0.865\n",
      "eval loss for epoch  0 :  0.34098183184862135\n",
      "Training  1  Epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:19<00:00, 10.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy for epoch  1 :  0.905\n",
      "training loss for epoch  1 :  0.24948312597349287\n",
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:08<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval accuracy for epoch  1 :  0.865\n",
      "eval loss for epoch  1 :  0.34098183184862135\n",
      "Training  2  Epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:19<00:00, 10.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy for epoch  2 :  0.916875\n",
      "training loss for epoch  2 :  0.25234994273632766\n",
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:08<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval accuracy for epoch  2 :  0.865\n",
      "eval loss for epoch  2 :  0.34098183184862135\n",
      "Evaluating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:07<00:00, 33.93it/s]\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(bert.parameters(), lr= 2e-5, eps = 1e-8)\n",
    "steps = len(baby_phish_train_dataloader)\n",
    "scheduler = transformers.get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0 , num_training_steps = steps)\n",
    "\n",
    "predictions, loss = train(bert, baby_phish_train_dataloader, baby_spam_valid_dataloader, optimizer, scheduler, device,3)\n",
    "\n",
    "v_loss, stats_test = test(bert, baby_phish_test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.891\n",
      "True pos 0.4405\n",
      "True neg 0.4505\n",
      "False pos 0.0525\n",
      "False neg 0.0565\n"
     ]
    }
   ],
   "source": [
    "print (\"acc:\", stats_test[0])\n",
    "print (\"True pos\", stats_test[1])\n",
    "print (\"True neg\", stats_test[2])\n",
    "print (\"False pos\", stats_test[3])\n",
    "print (\"False neg\", stats_test[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another strong preformance by bert, with a 89% acc and a 5% false postive. Conclusion: Bert is by far the better model when compared with a similar sized GPT model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
