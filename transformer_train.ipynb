{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d1a3dcf-ed25-470b-9bfb-1d2988114f68",
   "metadata": {},
   "source": [
    "## Transformer Training\n",
    "\n",
    "Alex McDonald\n",
    "\n",
    "In this jupyter notebook we will load the vocab and examples, then train a transformer on the spam and phishing URL examples. We will be using the GLoVE pre-trained embeddings, mostly to cut down on the amount of training needed for the rest of the transformer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a31eb708-edbf-416d-98a6-04c8151b623e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b669f75e-6407-46a2-b327-9d236eded846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the -0.038194 -0.24487 0.72812 -0.39961 0.083172 0.043953 -0.39141 0.3344 -0.57545 0.087459 0.28787 -0.06731 0.30906 -0.26384 -0.13231 -0.20757 0.33395 -0.33848 -0.31743 -0.48336 0.1464 -0.37304 0.34577 0.052041 0.44946 -0.46971 0.02628 -0.54155 -0.15518 -0.14107 -0.039722 0.28277 0.14393 0.23464 -0.31021 0.086173 0.20397 0.52624 0.17164 -0.082378 -0.71787 -0.41531 0.20335 -0.12763 0.41367 0.55187 0.57908 -0.33477 -0.36559 -0.54857 -0.062892 0.26584 0.30205 0.99775 -0.80481 -3.0243 0.01254 -0.36942 2.2167 0.72201 -0.24978 0.92136 0.034514 0.46745 1.1079 -0.19358 -0.074575 0.23353 -0.052062 -0.22044 0.057162 -0.15806 -0.30798 -0.41625 0.37972 0.15006 -0.53212 -0.2055 -1.2526 0.071624 0.70565 0.49744 -0.42063 0.26148 -1.538 -0.30223 -0.073438 -0.28312 0.37104 -0.25217 0.016215 -0.017099 -0.38984 0.87424 -0.72569 -0.51058 -0.52028 -0.1459 0.8278 0.27062\n",
      "\n",
      "Loaded 400000 words from glove\n",
      "0\n",
      "[-0.038194 -0.24487   0.72812  -0.39961   0.083172  0.043953 -0.39141\n",
      "  0.3344   -0.57545   0.087459  0.28787  -0.06731   0.30906  -0.26384\n",
      " -0.13231  -0.20757   0.33395  -0.33848  -0.31743  -0.48336   0.1464\n",
      " -0.37304   0.34577   0.052041  0.44946  -0.46971   0.02628  -0.54155\n",
      " -0.15518  -0.14107  -0.039722  0.28277   0.14393   0.23464  -0.31021\n",
      "  0.086173  0.20397   0.52624   0.17164  -0.082378 -0.71787  -0.41531\n",
      "  0.20335  -0.12763   0.41367   0.55187   0.57908  -0.33477  -0.36559\n",
      " -0.54857  -0.062892  0.26584   0.30205   0.99775  -0.80481  -3.0243\n",
      "  0.01254  -0.36942   2.2167    0.72201  -0.24978   0.92136   0.034514\n",
      "  0.46745   1.1079   -0.19358  -0.074575  0.23353  -0.052062 -0.22044\n",
      "  0.057162 -0.15806  -0.30798  -0.41625   0.37972   0.15006  -0.53212\n",
      " -0.2055   -1.2526    0.071624  0.70565   0.49744  -0.42063   0.26148\n",
      " -1.538    -0.30223  -0.073438 -0.28312   0.37104  -0.25217   0.016215\n",
      " -0.017099 -0.38984   0.87424  -0.72569  -0.51058  -0.52028  -0.1459\n",
      "  0.8278    0.27062 ]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#Load the vocabulary space, adapted from Homework 2\n",
    "glove_file = \"./datasets/glove.6B.100d.txt\" #or 50d\n",
    "\n",
    "embeddings_dict = {}\n",
    "\n",
    "with open(glove_file, 'r', encoding='utf8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i == 0:\n",
    "            print(line)\n",
    "        line = line.strip().split(' ')\n",
    "        word = line[0]\n",
    "        embed = np.asarray(line[1:], \"float\")\n",
    "\n",
    "        embeddings_dict[word] = embed\n",
    "\n",
    "print('Loaded {} words from glove'.format(len(embeddings_dict)))\n",
    "\n",
    "embedding_matrix = np.zeros((len(embeddings_dict)+1, 100)) #add 1 for padding\n",
    "\n",
    "word2id = {}\n",
    "for i, word in enumerate(embeddings_dict.keys()):\n",
    "\n",
    "    word2id[word] = i                                #Map each word to an index\n",
    "    embedding_matrix[i] = embeddings_dict[word]      #That index holds the Glove embedding in the embedding matrix\n",
    "\n",
    "# Our joint vocabulary for both models / sanity check to see if we've loaded it correctly:\n",
    "print(word2id['the'])\n",
    "print(embedding_matrix[word2id['the']])\n",
    "\n",
    "word2id['<pad>'] = embedding_matrix.shape[0] - 1\n",
    "print(embedding_matrix[word2id['<pad>']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a4d283-e916-472e-b2fb-a53118482a66",
   "metadata": {},
   "source": [
    "For the URLs, we plan on pre-processing the string to split by characters such as \".\" or \"/\". We will likely need embeddings for things like \".com\" or \"https\". First, we need to check if these embeddings already exist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e1d9ee7-a13a-4efe-9bd1-1e4d5a9af84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found tokens []\n",
      "Could not find ['http', 'https', '.com', 'com', '.org', 'org', '.net', 'net']\n"
     ]
    }
   ],
   "source": [
    "def embedding_exists(s):\n",
    "    if not (s in word2id): return False\n",
    "    if not (word2id[s] in embedding_matrix): return False\n",
    "    return True\n",
    "\n",
    "test_tokens = [\"http\", \"https\", \".com\", \"com\", \".org\", \"org\", \".net\", \"net\"] #can add more, but likely that <unk> token will be frequent in the URL model\n",
    "found = []\n",
    "not_found = []\n",
    "for token in test_tokens:\n",
    "    if (embedding_exists(token)): \n",
    "        found.append(token)\n",
    "    else: \n",
    "        not_found.append(token)\n",
    "\n",
    "print(\"Found tokens %s\" % found)\n",
    "print(\"Could not find %s\" % not_found)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7865dd69-f632-4743-8bbe-cfb2fb9d0a67",
   "metadata": {},
   "source": [
    "It looks like there does not exist common url components in the Glove embeddings, so we will need to likely train our own embeddings for the URL model. This might give the model an advantage though, because patterns like \"http\" vs. \"https\" might help the model distinguish between different url types. Given how many different combinations of URLs can exist though (such as two words put together without any hyphenation) may still lead to a large number of $<unk>$ tokens, which will be another problem to address.\n",
    "\n",
    "However, the GloVE embeddings should be adequate for the spam detection model. We will still need to be careful though, because the glove embeddings carry some amount of bias with them, which may become amplified by the model.\n",
    "\n",
    "To save on computational resources, we will start with a smaller subset of the data, then increase it for the final training. Let's load the spam datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3b59c5c-64de-49de-849f-389947431df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_full = pd.read_csv(\"./datasets/SpamHam/train.csv\", nrows=2000)\n",
    "\n",
    "split_ratio = 0.8\n",
    "train_size = int(split_ratio*spam_full.shape[0])\n",
    "spam_train = spam_full.iloc[:train_size]\n",
    "spam_valid = spam_full.iloc[train_size:]\n",
    "max_length = 120\n",
    "\n",
    "from nltk import word_tokenize\n",
    "\n",
    "def tokenize_example(line):\n",
    "    example = []\n",
    "    tokenized = word_tokenize(line)\n",
    "    i = 0\n",
    "    for token in tokenized:\n",
    "        if not (token in word2id): continue #not using <unk> for spam dataset\n",
    "        i += 1\n",
    "        if (i > max_length): break\n",
    "        example.append(word2id[token])\n",
    "        \n",
    "    #add padding\n",
    "    padding = word2id[\"<pad>\"]\n",
    "    for i in range(max_size - len(example)):\n",
    "        example.append(padding)\n",
    "    return np.array(example)\n",
    "\n",
    "def tokenize(df):\n",
    "    examples = []\n",
    "    for index, row in df.iterrows():\n",
    "        example = tokenize_example(row[\"text\"])\n",
    "        if (len(example) > 0 and len(example.shape) > 0): examples.append((example, row[\"label\"]))\n",
    "    return examples\n",
    "\n",
    "tokenized_spam_train = tokenize(spam_train)\n",
    "tokenized_spam_valid = tokenize(spam_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b92e43c-2920-46cd-aa0c-9411fbccf3b3",
   "metadata": {},
   "source": [
    "Here we will create a simple pytorch transformer. A major limitation is the amount of computational power and time that we have to be able to train it, so our model will be smaller than the typical transformer. However, we are not using it like a typical transformer either, because its output space is a simple 'yes' or 'no,' so it is unlikely to need many parameters to begin with. We will start with an encoder model, but if it performs poorly we can try a decoder model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e0e112f2-725e-48dc-8c1a-cf9c1775f08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_matrix, model_size, n_heads, n_layers, hidden_size, embedding_dims=100):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_matrix))\n",
    "        self.pos_encoding = PositionalEncoding(max_length)\n",
    "        self.input_linear = nn.Linear(max_length + embedding_dims, model_size)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(model_size, n_heads, hidden_size)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layers, n_layers)\n",
    "        self.output_layer = nn.Linear(model_size, 2) #map to 'yes' or 'no'\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.model_size = model_size\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        #print(\"intput.shape: \", input.shape, len(input.shape))\n",
    "        embedded = self.embedding(input) * math.sqrt(self.model_size) #recommended from documentation\n",
    "        #print(\"embedding shape: \", embedded.shape)\n",
    "        poe = self.pos_encoding(input).squeeze(1)\n",
    "        #print(\"poe shape: \", poe.shape)\n",
    "        input = torch.cat((embedded, poe), 1) #add positional encoding to input, need it per token\n",
    "        #print(\"cat shape: \", input.shape)\n",
    "\n",
    "        input = self.input_linear(input) #get a representation that has the model size for the positionally encoded embeddings\n",
    "        #print(\"after input linear: \", input.shape)\n",
    "        \n",
    "        output = self.encoder(input)[-1] #take the last vector\n",
    "        #print(\"after encoder: \", output.shape)\n",
    "        output = self.output_layer(output)\n",
    "        #print(\"after output linear: \", output.shape)\n",
    "        output = self.softmax(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, model_size, max_len=5000): #from torch documentation\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, model_size, 2) * (-math.log(10000.0) / model_size))\n",
    "        pe = torch.zeros(max_len, 1, model_size)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e024499f-d442-467f-b32d-69d7426245eb",
   "metadata": {},
   "source": [
    "And here we will define the training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "48c82653-59ec-45d9-a3a9-94bd0dfb0614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 1 --- \n",
      "epoch: 0 batch: 1 loss: 0.03933775186538696\n",
      "epoch: 0 batch: 51 loss: 0.7276829242706299\n",
      "epoch: 0 batch: 101 loss: 0.6809286111593247\n",
      "epoch: 0 batch: 151 loss: 0.6708504658937454\n",
      "epoch: 0 batch: 201 loss: 0.7368650126457215\n",
      "epoch: 0 batch: 251 loss: 0.6868789601325989\n",
      "epoch: 0 batch: 301 loss: 0.6721823161840439\n",
      "epoch: 0 batch: 351 loss: 0.5970106148719787\n",
      "epoch: 0 batch: 401 loss: 0.7065162110328674\n",
      "epoch: 0 batch: 451 loss: 0.7059426510334015\n",
      "epoch: 0 batch: 501 loss: 0.7092907154560089\n",
      "epoch: 0 batch: 551 loss: 0.6587582802772523\n",
      "epoch: 0 batch: 601 loss: 0.5527327984571457\n",
      "epoch: 0 batch: 651 loss: 0.6936495363712311\n",
      "epoch: 0 batch: 701 loss: 0.6607704389095307\n",
      "epoch: 0 batch: 751 loss: 0.6509990948438644\n",
      "epoch: 0 batch: 801 loss: 0.6932370072603226\n",
      "epoch: 0 batch: 851 loss: 0.6856944197416306\n",
      "epoch: 0 batch: 901 loss: 0.6230903381109237\n",
      "epoch: 0 batch: 951 loss: 0.6808966642618179\n",
      "epoch: 0 batch: 1001 loss: 0.6230281972885132\n",
      "epoch: 0 batch: 1051 loss: 0.693117372393608\n",
      "epoch: 0 batch: 1101 loss: 0.7200752651691437\n",
      "epoch: 0 batch: 1151 loss: 0.6935782051086425\n",
      "epoch: 0 batch: 1201 loss: 0.7153195959329605\n",
      "epoch: 0 batch: 1251 loss: 0.6806621479988099\n",
      "epoch: 0 batch: 1301 loss: 0.6663516801595688\n",
      "epoch: 0 batch: 1351 loss: 0.7239309465885162\n",
      "epoch: 0 batch: 1401 loss: 0.7083341354131698\n",
      "epoch: 0 batch: 1451 loss: 0.6326243686676025\n",
      "epoch: 0 batch: 1501 loss: 0.668864871263504\n",
      "epoch: 0 batch: 1551 loss: 0.6360404443740845\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "spam_model = TransformerModel(embedding_matrix, model_size=60, n_heads=2, n_layers=4, hidden_size=60)\n",
    "\n",
    "import traceback\n",
    "criteria = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(spam_model.parameters())\n",
    "\n",
    "epochs = 1\n",
    "batch_size = 32\n",
    "print_frequency = 50\n",
    "\n",
    "spam_train_dataloader = torch.utils.data.DataLoader(tokenized_spam_train)\n",
    "spam_valid_dataloader = torch.utils.data.DataLoader(tokenized_spam_valid)\n",
    "\n",
    "one_hot = torch.tensor(np.array([[1, 0], [0, 1]]), dtype=torch.float)\n",
    "\n",
    "losses = []\n",
    "for i in range(epochs):\n",
    "    print(\"--- Epoch %s --- \" % (i+1))\n",
    "\n",
    "    spam_model.train()\n",
    "    avg_loss = 0\n",
    "\n",
    "    for step, data in enumerate(spam_train_dataloader):\n",
    "        x,y = data\n",
    "        x = x.squeeze()\n",
    "        if (len(x.shape) == 0): continue\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = spam_model(x)\n",
    "        output = output.unsqueeze(0)\n",
    "       # print(\"output:\", output)\n",
    "        #print(\"y:\", one_hot[y])\n",
    "        loss = criteria(output, one_hot[y])\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_loss += loss.item()\n",
    "\n",
    "        if step % print_frequency == 1:\n",
    "            if (step > 1): losses.append(avg_loss / print_frequency)\n",
    "            print('epoch: {} batch: {} loss: {}'.format(\n",
    "                i,\n",
    "                step,\n",
    "                avg_loss / print_frequency\n",
    "            ))\n",
    "            avg_loss = 0\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.xlabel(\"Step (Print frequency %s)\" % print_frequency)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec4c57c-609e-4a31-a9ff-8e395357360b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "962ad323-a704-4470-a8ee-34100ded6f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From Homework 3:\n",
    "def predict(model, valid_dataloader):\n",
    "\n",
    "    sigmoid = nn.Sigmoid()\n",
    "\n",
    "    total_examples = 0 #len(valid_dataloader.dataset)\n",
    "    total_true = 0\n",
    "    total_false = 0\n",
    "\n",
    "    true_positive = 0\n",
    "    false_positive = 0\n",
    "    true_negative = 0\n",
    "    false_negative = 0\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    for x, y in valid_dataloader:\n",
    "        x = x.squeeze()\n",
    "        if (len(x.shape) == 0): continue\n",
    "        total_examples += 1\n",
    "        output = model(x)\n",
    "        \n",
    "        i += 1\n",
    "        print(output.shape, output, y)\n",
    "        print(output)\n",
    "        if (i > 10): return\n",
    "\n",
    "        output = output.unsqueeze(0) #remove\n",
    "        \n",
    "        for i in range(output.shape[0]):\n",
    "            if (output[i][0] < 0.5):\n",
    "                if (y[0] == 0):\n",
    "                    true_negative += 1\n",
    "                    total_false += 1\n",
    "                else:\n",
    "                    false_negative += 1\n",
    "                    total_true += 1\n",
    "            else:\n",
    "                if (y[0] == 0):\n",
    "                    false_positive += 1\n",
    "                    total_false += 1\n",
    "                else:\n",
    "                    true_positive += 1\n",
    "                    total_true += 1\n",
    "\n",
    "    accuracy = (true_positive + true_negative) / total_examples\n",
    "    print('accuracy: {}'.format(accuracy))\n",
    "    print('True positive: {}'.format(true_positive/total_true))\n",
    "    print('True negative: {}'.format(true_negative/total_false))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586fd475-1657-43bf-8837-d08ab61eb35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2]) tensor([0.0110, 0.9890], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0110, 0.9890], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0549, 0.9451], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.0549, 0.9451], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9940, 0.0060], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9940, 0.0060], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9965, 0.0035], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9965, 0.0035], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0195, 0.9805], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0195, 0.9805], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0537, 0.9463], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0537, 0.9463], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9965, 0.0035], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9965, 0.0035], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0160, 0.9840], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.0160, 0.9840], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9874, 0.0126], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9874, 0.0126], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0094, 0.9906], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0094, 0.9906], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0135, 0.9865], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0135, 0.9865], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9776, 0.0224], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9776, 0.0224], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9946, 0.0054], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9946, 0.0054], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9954, 0.0046], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9954, 0.0046], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0082, 0.9918], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0082, 0.9918], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9950, 0.0050], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9950, 0.0050], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0118, 0.9882], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0118, 0.9882], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9833, 0.0167], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9833, 0.0167], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9951, 0.0049], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9951, 0.0049], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0360, 0.9640], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.0360, 0.9640], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0186, 0.9814], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0186, 0.9814], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.1257, 0.8743], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.1257, 0.8743], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9772, 0.0228], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.9772, 0.0228], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0287, 0.9713], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0287, 0.9713], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0063, 0.9937], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.0063, 0.9937], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9941, 0.0059], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9941, 0.0059], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.1262, 0.8738], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.1262, 0.8738], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9894, 0.0106], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.9894, 0.0106], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0289, 0.9711], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.0289, 0.9711], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9644, 0.0356], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.9644, 0.0356], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9891, 0.0109], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9891, 0.0109], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0240, 0.9760], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.0240, 0.9760], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9872, 0.0128], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9872, 0.0128], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9961, 0.0039], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9961, 0.0039], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0067, 0.9933], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0067, 0.9933], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9924, 0.0076], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9924, 0.0076], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9938, 0.0062], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.9938, 0.0062], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0056, 0.9944], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.0056, 0.9944], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9935, 0.0065], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.9935, 0.0065], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9943, 0.0057], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9943, 0.0057], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9955, 0.0045], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9955, 0.0045], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.3386, 0.6614], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.3386, 0.6614], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9885, 0.0115], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9885, 0.0115], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9956, 0.0044], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9956, 0.0044], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.7147, 0.2853], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.7147, 0.2853], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0101, 0.9899], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0101, 0.9899], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.8900, 0.1100], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.8900, 0.1100], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0081, 0.9919], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0081, 0.9919], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0800, 0.9200], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0800, 0.9200], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0154, 0.9846], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.0154, 0.9846], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0094, 0.9906], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.0094, 0.9906], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9868, 0.0132], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9868, 0.0132], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0750, 0.9250], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0750, 0.9250], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9938, 0.0062], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9938, 0.0062], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0066, 0.9934], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0066, 0.9934], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0128, 0.9872], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0128, 0.9872], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0140, 0.9860], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0140, 0.9860], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9939, 0.0061], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9939, 0.0061], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0072, 0.9928], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.0072, 0.9928], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9953, 0.0047], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9953, 0.0047], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9702, 0.0298], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9702, 0.0298], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9861, 0.0139], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9861, 0.0139], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.3158, 0.6842], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.3158, 0.6842], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0108, 0.9892], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0108, 0.9892], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9927, 0.0073], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9927, 0.0073], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9918, 0.0082], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9918, 0.0082], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.1270, 0.8730], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.1270, 0.8730], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.1062, 0.8938], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.1062, 0.8938], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.8536, 0.1464], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.8536, 0.1464], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0129, 0.9871], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0129, 0.9871], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0159, 0.9841], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0159, 0.9841], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9959, 0.0041], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9959, 0.0041], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0203, 0.9797], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0203, 0.9797], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0097, 0.9903], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0097, 0.9903], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.2086, 0.7914], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.2086, 0.7914], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0218, 0.9782], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0218, 0.9782], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9956, 0.0044], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9956, 0.0044], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9954, 0.0046], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9954, 0.0046], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9962, 0.0038], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9962, 0.0038], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9954, 0.0046], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9954, 0.0046], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.7497, 0.2503], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.7497, 0.2503], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0073, 0.9927], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0073, 0.9927], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0100, 0.9900], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0100, 0.9900], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9958, 0.0042], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9958, 0.0042], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.2339, 0.7661], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.2339, 0.7661], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9945, 0.0055], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9945, 0.0055], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9772, 0.0228], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9772, 0.0228], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9937, 0.0063], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9937, 0.0063], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9953, 0.0047], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9953, 0.0047], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0162, 0.9838], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0162, 0.9838], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0064, 0.9936], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0064, 0.9936], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.3848, 0.6152], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.3848, 0.6152], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9833, 0.0167], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9833, 0.0167], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9895, 0.0105], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9895, 0.0105], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9913, 0.0087], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9913, 0.0087], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9919, 0.0081], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9919, 0.0081], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9954, 0.0046], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9954, 0.0046], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0054, 0.9946], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0054, 0.9946], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0105, 0.9895], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.0105, 0.9895], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9958, 0.0042], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9958, 0.0042], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9948, 0.0052], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9948, 0.0052], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9953, 0.0047], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9953, 0.0047], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0101, 0.9899], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0101, 0.9899], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0132, 0.9868], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.0132, 0.9868], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9917, 0.0083], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.9917, 0.0083], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9956, 0.0044], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9956, 0.0044], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9945, 0.0055], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9945, 0.0055], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9925, 0.0075], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9925, 0.0075], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9940, 0.0060], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9940, 0.0060], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9507, 0.0493], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.9507, 0.0493], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9806, 0.0194], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.9806, 0.0194], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9924, 0.0076], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9924, 0.0076], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.4769, 0.5231], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.4769, 0.5231], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.1006, 0.8994], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.1006, 0.8994], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0505, 0.9495], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0505, 0.9495], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.7520, 0.2480], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.7520, 0.2480], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9820, 0.0180], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.9820, 0.0180], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0173, 0.9827], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0173, 0.9827], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0193, 0.9807], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0193, 0.9807], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.5503, 0.4497], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.5503, 0.4497], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9962, 0.0038], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9962, 0.0038], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0094, 0.9906], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0094, 0.9906], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9950, 0.0050], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9950, 0.0050], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0088, 0.9912], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.0088, 0.9912], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0165, 0.9835], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0165, 0.9835], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9836, 0.0164], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9836, 0.0164], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9918, 0.0082], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9918, 0.0082], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.1622, 0.8378], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.1622, 0.8378], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9942, 0.0058], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9942, 0.0058], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9866, 0.0134], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9866, 0.0134], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9950, 0.0050], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9950, 0.0050], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0198, 0.9802], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0198, 0.9802], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.2792, 0.7208], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.2792, 0.7208], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0070, 0.9930], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0070, 0.9930], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9962, 0.0038], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9962, 0.0038], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0759, 0.9241], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0759, 0.9241], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9668, 0.0332], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9668, 0.0332], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0389, 0.9611], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0389, 0.9611], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0410, 0.9590], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0410, 0.9590], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.8311, 0.1689], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.8311, 0.1689], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0172, 0.9828], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0172, 0.9828], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9934, 0.0066], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.9934, 0.0066], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0088, 0.9912], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.0088, 0.9912], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.1627, 0.8373], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.1627, 0.8373], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.4565, 0.5435], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.4565, 0.5435], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.8690, 0.1310], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.8690, 0.1310], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9959, 0.0041], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9959, 0.0041], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9949, 0.0051], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.9949, 0.0051], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0280, 0.9720], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0280, 0.9720], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9961, 0.0039], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.9961, 0.0039], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.6072, 0.3928], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.6072, 0.3928], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9960, 0.0040], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.9960, 0.0040], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.3436, 0.6564], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.3436, 0.6564], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0190, 0.9810], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.0190, 0.9810], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0086, 0.9914], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.0086, 0.9914], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0085, 0.9915], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0085, 0.9915], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0054, 0.9946], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0054, 0.9946], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0076, 0.9924], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0076, 0.9924], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9939, 0.0061], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9939, 0.0061], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0630, 0.9370], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.0630, 0.9370], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0264, 0.9736], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0264, 0.9736], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9904, 0.0096], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9904, 0.0096], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0089, 0.9911], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.0089, 0.9911], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0058, 0.9942], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.0058, 0.9942], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9955, 0.0045], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9955, 0.0045], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9952, 0.0048], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9952, 0.0048], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0187, 0.9813], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0187, 0.9813], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9957, 0.0043], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9957, 0.0043], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.8667, 0.1333], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.8667, 0.1333], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0314, 0.9686], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0314, 0.9686], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0530, 0.9470], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.0530, 0.9470], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9799, 0.0201], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9799, 0.0201], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0094, 0.9906], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0094, 0.9906], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0097, 0.9903], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0097, 0.9903], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.5833, 0.4167], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.5833, 0.4167], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.1884, 0.8116], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.1884, 0.8116], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.3790, 0.6210], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.3790, 0.6210], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0098, 0.9902], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.0098, 0.9902], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9963, 0.0037], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9963, 0.0037], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9944, 0.0056], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9944, 0.0056], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9945, 0.0055], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.9945, 0.0055], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0237, 0.9763], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.0237, 0.9763], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.8837, 0.1163], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.8837, 0.1163], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0873, 0.9127], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0873, 0.9127], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9879, 0.0121], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.9879, 0.0121], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0426, 0.9574], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.0426, 0.9574], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0113, 0.9887], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.0113, 0.9887], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9405, 0.0595], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9405, 0.0595], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0203, 0.9797], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.0203, 0.9797], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0094, 0.9906], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0094, 0.9906], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9928, 0.0072], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9928, 0.0072], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0194, 0.9806], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.0194, 0.9806], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.8895, 0.1105], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.8895, 0.1105], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.2429, 0.7571], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.2429, 0.7571], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.7799, 0.2201], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.7799, 0.2201], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0259, 0.9741], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.0259, 0.9741], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.4796, 0.5204], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.4796, 0.5204], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9869, 0.0131], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.9869, 0.0131], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0142, 0.9858], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0142, 0.9858], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9714, 0.0286], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9714, 0.0286], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.3324, 0.6676], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.3324, 0.6676], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9845, 0.0155], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.9845, 0.0155], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0269, 0.9731], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0269, 0.9731], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0067, 0.9933], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0067, 0.9933], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0045, 0.9955], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0045, 0.9955], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9929, 0.0071], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9929, 0.0071], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0060, 0.9940], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0060, 0.9940], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0068, 0.9932], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0068, 0.9932], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.4598, 0.5402], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.4598, 0.5402], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0078, 0.9922], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0078, 0.9922], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0875, 0.9125], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0875, 0.9125], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9957, 0.0043], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9957, 0.0043], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9934, 0.0066], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9934, 0.0066], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9950, 0.0050], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.9950, 0.0050], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0060, 0.9940], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0060, 0.9940], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9941, 0.0059], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9941, 0.0059], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9964, 0.0036], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9964, 0.0036], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.1847, 0.8153], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.1847, 0.8153], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0113, 0.9887], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0113, 0.9887], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.6327, 0.3673], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.6327, 0.3673], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9829, 0.0171], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.9829, 0.0171], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9953, 0.0047], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9953, 0.0047], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9934, 0.0066], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.9934, 0.0066], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0090, 0.9910], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0090, 0.9910], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0252, 0.9748], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0252, 0.9748], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.7383, 0.2617], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.7383, 0.2617], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9356, 0.0644], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.9356, 0.0644], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0059, 0.9941], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0059, 0.9941], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9961, 0.0039], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9961, 0.0039], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.6861, 0.3139], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.6861, 0.3139], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9876, 0.0124], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9876, 0.0124], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9931, 0.0069], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.9931, 0.0069], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9861, 0.0139], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9861, 0.0139], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9942, 0.0058], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9942, 0.0058], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0729, 0.9271], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.0729, 0.9271], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0480, 0.9520], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0480, 0.9520], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0287, 0.9713], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0287, 0.9713], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.4013, 0.5987], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.4013, 0.5987], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.2343, 0.7657], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.2343, 0.7657], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0836, 0.9164], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.0836, 0.9164], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9946, 0.0054], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9946, 0.0054], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0733, 0.9267], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0733, 0.9267], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9952, 0.0048], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9952, 0.0048], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9653, 0.0347], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9653, 0.0347], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0323, 0.9677], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.0323, 0.9677], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0160, 0.9840], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.0160, 0.9840], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9071, 0.0929], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9071, 0.0929], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9959, 0.0041], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9959, 0.0041], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0115, 0.9885], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0115, 0.9885], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9891, 0.0109], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9891, 0.0109], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.1447, 0.8553], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.1447, 0.8553], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.3412, 0.6588], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.3412, 0.6588], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9764, 0.0236], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9764, 0.0236], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0089, 0.9911], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0089, 0.9911], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9883, 0.0117], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.9883, 0.0117], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.6065, 0.3935], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.6065, 0.3935], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9719, 0.0281], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.9719, 0.0281], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9956, 0.0044], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.9956, 0.0044], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9732, 0.0268], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9732, 0.0268], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9759, 0.0241], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9759, 0.0241], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0524, 0.9476], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.0524, 0.9476], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0343, 0.9657], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.0343, 0.9657], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0180, 0.9820], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0180, 0.9820], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9924, 0.0076], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9924, 0.0076], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9944, 0.0056], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9944, 0.0056], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0088, 0.9912], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.0088, 0.9912], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0421, 0.9579], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.0421, 0.9579], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0240, 0.9760], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0240, 0.9760], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0092, 0.9908], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0092, 0.9908], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0055, 0.9945], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0055, 0.9945], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9681, 0.0319], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9681, 0.0319], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9944, 0.0056], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9944, 0.0056], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0065, 0.9935], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.0065, 0.9935], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9801, 0.0199], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.9801, 0.0199], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.6827, 0.3173], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.6827, 0.3173], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9963, 0.0037], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9963, 0.0037], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.1766, 0.8234], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.1766, 0.8234], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9871, 0.0129], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9871, 0.0129], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9782, 0.0218], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.9782, 0.0218], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0077, 0.9923], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.0077, 0.9923], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0177, 0.9823], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.0177, 0.9823], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9957, 0.0043], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9957, 0.0043], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9861, 0.0139], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.9861, 0.0139], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0123, 0.9877], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.0123, 0.9877], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9962, 0.0038], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9962, 0.0038], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9941, 0.0059], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9941, 0.0059], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.5653, 0.4347], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.5653, 0.4347], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9942, 0.0058], grad_fn=<SoftmaxBackward0>) tensor([1])\n",
      "tensor([0.9942, 0.0058], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.9940, 0.0060], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.9940, 0.0060], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([2]) tensor([0.0055, 0.9945], grad_fn=<SoftmaxBackward0>) tensor([0])\n",
      "tensor([0.0055, 0.9945], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "predict(spam_model, spam_valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f9e744-6df7-4306-8215-bdc2ecf90f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
