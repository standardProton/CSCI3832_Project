{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Spam Validation Set Accuracy: 0.4951545745974428\n",
      "Spam Validation Set Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.50      0.51     14411\n",
      "           1       0.46      0.49      0.48     12728\n",
      "\n",
      "    accuracy                           0.50     27139\n",
      "   macro avg       0.49      0.49      0.49     27139\n",
      "weighted avg       0.50      0.50      0.50     27139\n",
      "\n",
      "108556    0\n",
      "108557    1\n",
      "108558    0\n",
      "108559    1\n",
      "108560    1\n",
      "         ..\n",
      "159995    1\n",
      "159996    1\n",
      "159997    0\n",
      "159998    1\n",
      "159999    0\n",
      "Name: label, Length: 51444, dtype: int64\n",
      "\n",
      "URL Validation Set Accuracy: 0.49739522587668145\n",
      "URL Validation Set Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.36      0.42     25631\n",
      "           1       0.50      0.63      0.56     25813\n",
      "\n",
      "    accuracy                           0.50     51444\n",
      "   macro avg       0.50      0.50      0.49     51444\n",
      "weighted avg       0.50      0.50      0.49     51444\n",
      "\n",
      "\n",
      "Spam Test Data Accuracy: 0.49705098443813944\n",
      "Spam Test Data Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.50      0.51     30448\n",
      "           1       0.47      0.50      0.48     27707\n",
      "\n",
      "    accuracy                           0.50     58155\n",
      "   macro avg       0.50      0.50      0.50     58155\n",
      "weighted avg       0.50      0.50      0.50     58155\n",
      "\n",
      "\n",
      "URLs Test Data Accuracy: 0.5002625\n",
      "URLs Test Data Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.36      0.42     80000\n",
      "           1       0.50      0.64      0.56     80000\n",
      "\n",
      "    accuracy                           0.50    160000\n",
      "   macro avg       0.50      0.50      0.49    160000\n",
      "weighted avg       0.50      0.50      0.49    160000\n",
      "\n",
      "\n",
      "Homebrew Test Data Accuracy: 0.5333333333333333\n",
      "Homebrew Test Data Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.77      0.59        13\n",
      "           1       0.67      0.35      0.46        17\n",
      "\n",
      "    accuracy                           0.53        30\n",
      "   macro avg       0.57      0.56      0.52        30\n",
      "weighted avg       0.58      0.53      0.52        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_curve, auc, precision_recall_curve, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "split_ratio = 0.8\n",
    "\n",
    "# Load datasets\n",
    "spam_test = pd.read_csv('./datasets/SpamHam/test.csv').fillna('')\n",
    "spam_test['label'] = spam_test['label']\n",
    "\n",
    "\n",
    "spam_ftrain = pd.read_csv('./datasets/SpamHam/train.csv').fillna('')\n",
    "spam_ftrain['label'] = spam_ftrain['label']\n",
    "spamsize = int(split_ratio*spam_ftrain.shape[0])\n",
    "spam_train=spam_ftrain.iloc[:spamsize]\n",
    "spam_valid=spam_ftrain.iloc[spamsize:]\n",
    "\n",
    "urls_test = pd.read_csv('datasets/PhishingURLs/test.csv').fillna('')\n",
    "urls_test['label'] = urls_test['label'].apply(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "urls_ftrain = pd.read_csv('datasets/PhishingURLs/test.csv').fillna('')\n",
    "urls_ftrain['label'] = urls_ftrain['label'].apply(lambda x: 1 if x == 1 else 0)\n",
    "urlsize = int(split_ratio*spam_ftrain.shape[0])\n",
    "urls_train=urls_ftrain.iloc[:urlsize]\n",
    "urls_valid=urls_ftrain.iloc[urlsize:]\n",
    "\n",
    "homebrew_data = pd.read_csv('HomebrewDataset.csv').fillna('')\n",
    "homebrew_data['label'] = homebrew_data['label'].apply(lambda x: 1 if x==1 else 0)\n",
    "\n",
    "# Split each dataset into training and testing sets\n",
    "#spam_train, spam_test = train_test_split(spam_full, test_size=0.2, random_state=42)\n",
    "#urls_train, urls_test = train_test_split(urls_full, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Combine the training data from all datasets\n",
    "#combined_train = pd.concat([spam_train, urls_train], ignore_index=True)\n",
    "#combined_valid = pd.concat([spam_valid, urls_valid], ignore_index=True)\n",
    "# Feature extraction for combined training data\n",
    "X_train_S = tfidf_vectorizer.fit_transform(spam_train['text'])\n",
    "y_train_S = spam_train['label']\n",
    "X_valid_S = tfidf_vectorizer.fit_transform(spam_valid['text'])\n",
    "y_valid_S = spam_valid['label']\n",
    "\n",
    "X_train_U = tfidf_vectorizer.fit_transform(urls_train['text'])\n",
    "y_train_U = spam_train['label']\n",
    "X_valid_U = tfidf_vectorizer.fit_transform(urls_valid['text'])\n",
    "y_valid_U = spam_valid['label']\n",
    "# Train Logistic Regression model\n",
    "#print(y_train)\n",
    "#print(X_train)\n",
    "model = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "model.fit(X_train_S, y_train_S)\n",
    "model.fit(X_train_U, y_train_U)\n",
    "\n",
    "def evaluate_model(X, y, model, dataset_name):\n",
    "    predictions = model.predict(X)\n",
    "    accuracy = accuracy_score(y, predictions)\n",
    "    #fpr, tpr, _ = roc_curve(y.map({'Ham': 0, 'Spam': 1}), model.predict_proba(X)[:, 1])\n",
    "    #roc_auc = auc(fpr, tpr)\n",
    "    #precision, recall, _ = precision_recall_curve(y.map({'Ham': 0, 'Spam': 1}), model.predict_proba(X)[:, 1])\n",
    "    #pr_auc = auc(recall, precision)\n",
    "    conf_matrix = confusion_matrix(y, predictions)\n",
    "\n",
    "    # Plotting\n",
    "    #plt.figure(figsize=(10, 5))\n",
    "    #plt.subplot(1, 2, 1)\n",
    "    #plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    #plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    #plt.xlim([0.0, 1.0])\n",
    "    #plt.ylim([0.0, 1.05])\n",
    "    #plt.xlabel('False Positive Rate')\n",
    "    #plt.ylabel('True Positive Rate')\n",
    "    #plt.title(f'ROC Curve for {dataset_name}')\n",
    "    #plt.legend(loc=\"lower right\")\n",
    "\n",
    "    #plt.subplot(1, 2, 2)\n",
    "    #plt.plot(recall, precision, color='blue', lw=2, label='Precision-Recall curve (area = %0.2f)' % pr_auc)\n",
    "    #plt.xlim([0.0, 1.0])\n",
    "    #plt.ylim([0.0, 1.05])\n",
    "    #plt.xlabel('Recall')\n",
    "    #plt.ylabel('Precision')\n",
    "    #plt.title(f'Precision-Recall Curve for {dataset_name}')\n",
    "    #plt.legend(loc=\"lower left\")\n",
    "    #plt.show()\n",
    "\n",
    "    #sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'])\n",
    "    #plt.title(f'Confusion Matrix for {dataset_name}')\n",
    "    #plt.xlabel('Predicted Label')\n",
    "    #plt.ylabel('True Label')\n",
    "    #plt.show()\n",
    "\n",
    "    print(f\"\\n{dataset_name} Accuracy:\", accuracy)\n",
    "    print(f\"{dataset_name} Classification Report:\\n\", classification_report(y, predictions))\n",
    "\n",
    "X_spam_valid = tfidf_vectorizer.transform(spam_valid['text'])\n",
    "Y_spam_valid = spam_valid['label']\n",
    "#print(Y_spam_valid)\n",
    "evaluate_model(X_spam_valid, Y_spam_valid, model, \"Spam Validation Set\")\n",
    "\n",
    "X_urls_valid = tfidf_vectorizer.transform(urls_valid['text'])\n",
    "y_urls_valid = urls_valid['label']\n",
    "print(y_urls_valid)\n",
    "evaluate_model(X_urls_valid, y_urls_valid, model, \"URL Validation Set\")\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate the models\n",
    "X_spam_test = tfidf_vectorizer.transform(spam_test['text'])\n",
    "y_spam_test = spam_test['label']\n",
    "evaluate_model(X_spam_test, y_spam_test, model, \"Spam Test Data\")\n",
    "\n",
    "X_urls_test = tfidf_vectorizer.transform(urls_test['text'])\n",
    "y_urls_test = urls_test['label']\n",
    "evaluate_model(X_urls_test, y_urls_test, model, \"URLs Test Data\")\n",
    "\n",
    "X_homebrew_test = tfidf_vectorizer.transform(homebrew_data['text'])\n",
    "y_homebrew_test = homebrew_data['label']\n",
    "evaluate_model(X_homebrew_test, y_homebrew_test, model, \"Homebrew Test Data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
